{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pd_p\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.pipeline import Pipeline as pipe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORANGE JUICE DATA\n",
    "###################\n",
    "data = pd.read_csv('OJ.csv')\n",
    "data = data.drop(columns='Id')\n",
    "data['Purchase'] = data['Purchase'].replace(['CH','MM'],[1,0])\n",
    "data['Store7'] = data['Store7'].replace(['Yes','No'],[1,0])\n",
    "data = data.drop('STORE',axis = 1)\n",
    "data_dummy = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADULT INCOME DATA (SAMPLE FROM AZURE ML)\n",
    "###################\n",
    "#data = pd.read_csv('adult.csv')\n",
    "#X = data.iloc[:,0:13]\n",
    "#X = X.drop(' education', axis=1)\n",
    "#y = data.iloc[:,-1]\n",
    "#X_dummy = pd.get_dummies(X)\n",
    "#y = y.replace([' >50K',' <=50K'],[1,0])\n",
    "#data_dummy = pd.concat([X_dummy,y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(data, target, split=0.7):\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X = data.drop(target,axis=1)\n",
    "  y = data[target]\n",
    "  global X_train, X_test, y_train, y_test, seed\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split)\n",
    "  import random\n",
    "  seed = random.randint(150,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(data_dummy, 'Purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(estimator=None, ensemble = False, method = 'Bagging', \n",
    "               fold=10, round=4, plot=None, show_results=True):\n",
    "  \n",
    "  #defining X_train and y_train    \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "  \n",
    "  #ignore co-linearity warnings for qda and lda \n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "  \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.svm import LinearSVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold  \n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from yellowbrick.classifier import roc_auc\n",
    "  from yellowbrick.classifier import ROCAUC\n",
    "  from yellowbrick.classifier import discrimination_threshold\n",
    "  from yellowbrick.classifier import precision_recall_curve\n",
    "  from yellowbrick.classifier import confusion_matrix\n",
    "  from yellowbrick.classifier import class_prediction_error\n",
    "  from yellowbrick.classifier import classification_report\n",
    "    \n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "  \n",
    "  #global model, full_name\n",
    "  \n",
    "  if estimator == None:\n",
    "    print(\"Please enter your custom model as on object or choose from model library. If you have previously defined the estimator, the output is generated using the same estimator\") \n",
    "  elif estimator == 'lr':\n",
    "    model = LogisticRegression(random_state=seed)\n",
    "    full_name = 'Logistic Regression'\n",
    "  elif estimator == 'knn':\n",
    "    model = KNeighborsClassifier()\n",
    "    full_name = 'K Nearest Neighbours'\n",
    "  elif estimator == 'nb':\n",
    "    model = GaussianNB()\n",
    "    full_name = 'Naive Bayes'\n",
    "  elif estimator == 'dt':\n",
    "    model = DecisionTreeClassifier(random_state=seed)\n",
    "    full_name = 'Decision Tree'\n",
    "  elif estimator == 'svm':\n",
    "    model = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "    full_name = 'Support Vector Machine'\n",
    "  elif estimator == 'rbfsvm':\n",
    "    model = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "    full_name = 'RBF SVM'\n",
    "  elif estimator == 'gpc':\n",
    "    model = GaussianProcessClassifier(random_state=seed)\n",
    "    full_name = 'Gaussian Process Classifier'\n",
    "  elif estimator == 'mlp':\n",
    "    model = MLPClassifier(max_iter=500, random_state=seed)\n",
    "    full_name = 'Multi Level Perceptron'    \n",
    "  elif estimator == 'ridge':\n",
    "    model = RidgeClassifier(random_state=seed)\n",
    "    full_name = 'Ridge Classifier'        \n",
    "  elif estimator == 'rf':\n",
    "    model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "    full_name = 'Random Forest Classifier'    \n",
    "  elif estimator == 'qda':\n",
    "    model = QuadraticDiscriminantAnalysis()\n",
    "    full_name = 'Quadratic Discriminant Analysis'    \n",
    "  elif estimator == 'ada':\n",
    "    model = AdaBoostClassifier(random_state=seed)\n",
    "    full_name = 'AdaBoost Classifier'        \n",
    "  elif estimator == 'gbc':\n",
    "    model = GradientBoostingClassifier(random_state=seed)\n",
    "    full_name = 'Gradient Boosting Classifier'          \n",
    "  elif estimator == 'lda':\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    full_name = 'Linear Discriminant Analysis'\n",
    "  elif estimator == 'et':\n",
    "    model = ExtraTreesClassifier(random_state=seed)\n",
    "    full_name = 'Extra Trees Classifier'\n",
    "  else:\n",
    "    model = estimator\n",
    "    full_name = \"Custom Model\"\n",
    "  \n",
    "  #checking ensemble method\n",
    "    \n",
    "  if ensemble and method == 'Bagging':\n",
    "    model = BaggingClassifier(model,bootstrap=True,n_estimators=10, random_state=seed)\n",
    "  elif ensemble and method == 'Boosting':\n",
    "    model = AdaBoostClassifier(model, random_state=seed)\n",
    "  elif method == 'Boosting':\n",
    "    model = AdaBoostClassifier(model, random_state=seed)\n",
    "     \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.00\n",
    "        pred_prob = 0.00\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.00\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa) \n",
    "       \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "  base_model_ = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  base_model_unpivot_ = pd.melt(base_model_,value_vars=['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa'])\n",
    "  base_model_unpivot_.columns = ['Metric', 'Measure']\n",
    "  base_model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  base_model_ = base_model_.append(base_model_avgs)\n",
    "  base_model_ = base_model_.round(round)  \n",
    " \n",
    "  if plot == 'None':\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(base_model_.to_html()))\n",
    "    \n",
    "  elif plot == 'auc':\n",
    "    from yellowbrick.classifier import ROCAUC\n",
    "    visualizer = ROCAUC(model)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.poof()\n",
    "    \n",
    "  elif plot == 'threshold':\n",
    "    from yellowbrick.classifier import DiscriminationThreshold\n",
    "    visualizer = DiscriminationThreshold(model)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.poof()\n",
    "    \n",
    "  elif plot == 'pr':\n",
    "    from yellowbrick.classifier import PrecisionRecallCurve\n",
    "    visualizer = PrecisionRecallCurve(model)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.poof()\n",
    "    \n",
    "  elif plot == 'confusion_matrix':\n",
    "    from yellowbrick.classifier import ConfusionMatrix\n",
    "    visualizer = ConfusionMatrix(model, fontsize=15, cmap=\"Greens\")\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.poof()\n",
    "    \n",
    "  elif plot == 'error':\n",
    "    from yellowbrick.classifier import ClassPredictionError\n",
    "    visualizer = ClassPredictionError(model)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.poof()\n",
    "        \n",
    "  elif plot == 'class_report':\n",
    "    from yellowbrick.classifier import ClassificationReport\n",
    "    visualizer = ClassificationReport(model, support=True)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.poof()\n",
    "\n",
    "  elif plot == 'boundary':\n",
    "        \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from yellowbrick.contrib.classifier import DecisionViz        \n",
    "    \n",
    "    X_train_transformed = X_train.select_dtypes(include='float64')\n",
    "    X_test_transformed = X_test.select_dtypes(include='float64')\n",
    "    X_train_transformed = StandardScaler().fit_transform(X_train_transformed)\n",
    "    X_test_transformed = StandardScaler().fit_transform(X_test_transformed)\n",
    "    pca = PCA(n_components=2)\n",
    "    X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "    X_test_transformed = pca.fit_transform(X_test_transformed)\n",
    "\n",
    "    y_train_transformed = np.array(y_train)\n",
    "    y_test_transformed = np.array(y_test)\n",
    "\n",
    "    viz = DecisionViz(model)\n",
    "    viz.fit(X_train_transformed, y_train_transformed, features=['Feature One', 'Feature Two'], classes=['A', 'B'])\n",
    "    viz.draw(X_test_transformed, y_test_transformed)\n",
    "    viz.poof()    \n",
    "    \n",
    "  elif plot == 'learning':\n",
    "    from yellowbrick.model_selection import LearningCurve\n",
    "    cv = fold\n",
    "    sizes = np.linspace(0.3, 1.0, 10)  \n",
    "    visualizer = LearningCurve(model, cv=cv, scoring='f1_weighted', train_sizes=sizes, n_jobs=4)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.poof()\n",
    "    \n",
    "  elif plot == 'rfe':\n",
    "    from yellowbrick.model_selection import RFECV    \n",
    "    visualizer = RFECV(model, cv=fold)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.poof()\n",
    "\n",
    "  elif plot == 'manifold':\n",
    "    from yellowbrick.features import Manifold\n",
    "    X_train_transformed = X_train.select_dtypes(include='float64') \n",
    "    visualizer = Manifold(manifold=\"tsne\")\n",
    "    visualizer.fit_transform(X_train_transformed, y_train)\n",
    "    visualizer.poof()\n",
    "    \n",
    "  elif plot == 'vc':\n",
    "    \n",
    "    if estimator == 'dt':\n",
    "       \n",
    "        from yellowbrick.model_selection import ValidationCurve\n",
    "        viz = ValidationCurve(model, param_name=\"max_depth\", param_range=np.arange(1,11), scoring='f1_weighted',cv=fold)\n",
    "        viz.fit(X_train, y_train)\n",
    "        viz.poof()\n",
    "        \n",
    "    elif estimator == 'svm':\n",
    "        pass\n",
    "\n",
    "  elif plot == 'dimension':\n",
    "    \n",
    "    from yellowbrick.features import RadViz\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    X_train_transformed = X_train.select_dtypes(include='float64') \n",
    "    X_train_transformed = StandardScaler().fit_transform(X_train_transformed)\n",
    "    y_train_transformed = np.array(y_train)\n",
    "    \n",
    "    pca = PCA(n_components=5)\n",
    "    X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "    \n",
    "    classes = [\"1\", \"0\"]\n",
    "    visualizer = RadViz(classes=classes)\n",
    "    visualizer.fit(X_train_transformed, y_train_transformed)           # Fit the data to the visualizer\n",
    "    visualizer.transform(X_train_transformed)        # Transform the data\n",
    "    visualizer.poof()              # Draw/show/poof the data\n",
    "        \n",
    "  elif plot == 'calibration':\n",
    "    \n",
    "    from sklearn.calibration import calibration_curve\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    model.fit(X_train, y_train)\n",
    "    prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "    prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % (full_name, ))\n",
    "\n",
    "    ax1.set_ylabel(\"Fraction of positives\")\n",
    "    ax1.set_ylim([0, 1])\n",
    "    ax1.set_xlim([0, 1])\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_title('Calibration plots  (reliability curve)')\n",
    "    ax1.set_facecolor('white')\n",
    "    ax1.grid(b=True, color='grey', linewidth=0.5, linestyle = '-')\n",
    "    plt.tight_layout()\n",
    "    plt.show()   \n",
    "        \n",
    "  elif plot == 'feature':\n",
    "    variables = abs(model.coef_[0])\n",
    "    col_names = np.array(X_train.columns)\n",
    "    coef_df = pd.DataFrame({'Variable': X_train.columns, 'Value': variables})\n",
    "    sorted_df = coef_df.sort_values(by='Value')\n",
    "    my_range=range(1,len(sorted_df.index)+1)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hlines(y=my_range, xmin=0, xmax=sorted_df['Value'], color='skyblue')\n",
    "    plt.plot(sorted_df['Value'], my_range, \"o\")\n",
    "    plt.yticks(my_range, sorted_df['Variable'])\n",
    "    plt.title(\"Feature Importance Plot\")\n",
    "    plt.xlabel('Variable Importance')\n",
    "    plt.ylabel('Features') \n",
    "    global var_imp_array_top_n\n",
    "    var_imp = sorted_df.reset_index(drop=True)\n",
    "    var_imp_array = np.array(var_imp['Variable'])\n",
    "    var_imp_array_top_n = var_imp_array[0:len(var_imp_array)]\n",
    "\n",
    "  elif plot == 'cv':\n",
    "    sns.set(rc={'figure.figsize':(8,5)})\n",
    "    sns.boxplot(x='Metric', y='Measure', data=base_model_unpivot_, width=0.5, linewidth=1, palette='Set2').set_title('Results from K-Fold Cross Validation')\n",
    "    \n",
    "  else:\n",
    "    if show_results:\n",
    "        from IPython.display import display, HTML\n",
    "        display(HTML(base_model_.to_html()))\n",
    "        return model\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(data_X=X_train, n=3):\n",
    "    global X_train\n",
    "    drop_list = var_imp_array_top_n[0:n]\n",
    "    X_train.drop(drop_list, axis=1, inplace=True)\n",
    "    #X_test.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_models() function\n",
    "\n",
    "def compare_models(model_library=None, fold=10, round=4, sort='Accuracy', blacklist=None):\n",
    "  \n",
    "  #ignore warnings\n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "    \n",
    "  #defining X_train and y_train\n",
    "  data_X = X_train\n",
    "  data_y=y_train\n",
    "\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  import random\n",
    "  import pandas.io.formats.style\n",
    "\n",
    "  lr = LogisticRegression(random_state=seed)\n",
    "  knn = KNeighborsClassifier()\n",
    "  nb = GaussianNB()\n",
    "  dt = DecisionTreeClassifier(random_state=seed)\n",
    "  svm = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "  rbfsvm = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "  gpc = GaussianProcessClassifier(random_state=seed)\n",
    "  mlp = MLPClassifier(max_iter=500, random_state=seed)\n",
    "  ridge = RidgeClassifier(random_state=seed)\n",
    "  rf = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "  qda = QuadraticDiscriminantAnalysis()\n",
    "  ada = AdaBoostClassifier(random_state=seed)\n",
    "  gbc = GradientBoostingClassifier(random_state=seed)\n",
    "  lda = LinearDiscriminantAnalysis()\n",
    "  et = ExtraTreesClassifier(random_state=seed)\n",
    "  \n",
    "  #blacklist models\n",
    "  #global model_library\n",
    "\n",
    "  if model_library != None:\n",
    "    \n",
    "    model_library = model_library\n",
    "    \n",
    "    model_names = []\n",
    "    \n",
    "    for names in model_library:\n",
    "        \n",
    "        model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "        \n",
    "        import re \n",
    "        \n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "            \n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final    \n",
    "    \n",
    "  else:\n",
    "        \n",
    "    if blacklist == None:\n",
    "        \n",
    "        model_library = [lr, knn, nb, dt, svm, rbfsvm, gpc, mlp, ridge, rf, qda, ada, gbc, lda, et]\n",
    "    \n",
    "        model_names = []\n",
    "    \n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "    \n",
    "        import re \n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model_library_values = ['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf', 'qda', \n",
    "                        'ada', 'gbc', 'lda', 'et']\n",
    "\n",
    "        location = []\n",
    "\n",
    "        for item in blacklist:\n",
    "            location.append(model_library_values.index(item))\n",
    "\n",
    "        model_library = [lr, knn, nb, dt, svm, rbfsvm, gpc, mlp, ridge, rf, qda, ada, gbc, lda, et]\n",
    "\n",
    "        for i in location:\n",
    "            del model_library[i]\n",
    "\n",
    "        #global model_names\n",
    "\n",
    "        model_names = []\n",
    "\n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "        import re\n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  global score_acc_running\n",
    "  score_acc_running = np.empty((0,0)) ##running total\n",
    "  avg_acc = np.empty((0,0))\n",
    "  avg_auc = np.empty((0,0))\n",
    "  avg_recall = np.empty((0,0))\n",
    "  avg_precision = np.empty((0,0))\n",
    "  avg_f1 = np.empty((0,0))\n",
    "  avg_kappa = np.empty((0,0))\n",
    "      \n",
    "  for model in model_library:\n",
    " \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "     \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "          model.fit(Xtrain,ytrain)\n",
    "          pred_prob = model.predict_proba(Xtest)\n",
    "          pred_prob = pred_prob[:,1]\n",
    "          pred_ = model.predict(Xtest)\n",
    "          sca = metrics.accuracy_score(ytest,pred_)\n",
    "          sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "          recall = metrics.recall_score(ytest,pred_)\n",
    "          precision = metrics.precision_score(ytest,pred_)\n",
    "          kappa = cohen_kappa_score(ytest,pred_)\n",
    "          f1 = metrics.f1_score(ytest,pred_)\n",
    "          score_acc = np.append(score_acc,sca)\n",
    "          score_auc = np.append(score_auc,sc)\n",
    "          score_recall = np.append(score_recall,recall)\n",
    "          score_precision = np.append(score_precision,precision)\n",
    "          score_f1 =np.append(score_f1,f1)\n",
    "          score_kappa =np.append(score_kappa,kappa)              \n",
    "        \n",
    "        else:        \n",
    "        \n",
    "          model.fit(Xtrain,ytrain)\n",
    "          pred_prob = 0.00\n",
    "          pred_prob = 0.00\n",
    "          pred_ = model.predict(Xtest)\n",
    "          sca = metrics.accuracy_score(ytest,pred_)\n",
    "          sc = 0.00\n",
    "          recall = metrics.recall_score(ytest,pred_)\n",
    "          precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "          kappa = cohen_kappa_score(ytest,pred_)\n",
    "          f1 = metrics.f1_score(ytest,pred_)\n",
    "          score_acc = np.append(score_acc,sca)\n",
    "          score_auc = np.append(score_auc,sc)\n",
    "          score_recall = np.append(score_recall,recall)\n",
    "          score_precision = np.append(score_precision,precision)\n",
    "          score_f1 =np.append(score_f1,f1)\n",
    "          score_kappa =np.append(score_kappa,kappa) \n",
    "        \n",
    "    avg_acc = np.append(avg_acc,np.mean(score_acc))\n",
    "    avg_auc = np.append(avg_auc,np.mean(score_auc))\n",
    "    avg_recall = np.append(avg_recall,np.mean(score_recall))\n",
    "    avg_precision = np.append(avg_precision,np.mean(score_precision))\n",
    "    avg_f1 = np.append(avg_f1,np.mean(score_f1))\n",
    "    avg_kappa = np.append(avg_kappa,np.mean(score_kappa))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "\n",
    "  model_list = model_names\n",
    "  \n",
    "  global compare_models_\n",
    "  \n",
    "  def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "  compare_models_ = pd.DataFrame({'Model':model_list, 'Accuracy':avg_acc, 'AUC':avg_auc, \n",
    "                     'Recall':avg_recall, 'Prec.':avg_precision, \n",
    "                     'F1':avg_f1, 'Kappa': avg_kappa}).round(round).sort_values(by=[sort], \n",
    "                      ascending=False).reset_index(drop=True).style.apply(highlight_max,subset=['Accuracy','AUC','Recall',\n",
    "                      'Prec.','F1','Kappa'])\n",
    "  compare_models_ = compare_models_.set_properties(**{'text-align': 'left'})\n",
    "  compare_models_ = compare_models_.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "                  \n",
    "  return compare_models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(estimator=None, fold=10, round=4, n_iter=10, optimize='accuracy',\n",
    "              ensemble = False, method = 'Bagging'):\n",
    "   \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold  \n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "    \n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "  \n",
    "  global best_model, best_model_param\n",
    "    \n",
    "  if estimator == 'knn':\n",
    "    \n",
    "    param_grid = {'n_neighbors': range(1,51),\n",
    "             'weights' : ['uniform', 'distance'],\n",
    "             'metric':[\"euclidean\", \"manhattan\"]\n",
    "                 }        \n",
    "    model_grid = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=param_grid, \n",
    "                                    scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1, iid=False)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'lr':\n",
    "\n",
    "    param_grid = {'C': [1,5,10,25,50,100],\n",
    "              \"penalty\": [ 'l1', 'l2'],\n",
    "              \"class_weight\": [\"balanced\", None]\n",
    "                 }\n",
    "    model_grid = RandomizedSearchCV(estimator=LogisticRegression(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False,n_jobs=-1)\n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'dt':\n",
    "        \n",
    "    param_grid = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "              \"max_features\": np.random.randint(3, len(X_train.columns),4),\n",
    "              \"min_samples_leaf\": [2,3,4],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'mlp':\n",
    "    \n",
    "    param_grid = {'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "             'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'hidden_layer_sizes': np.random.randint(5,15,5),\n",
    "             'activation': [\"tanh\", \"identity\", \"logistic\",\"relu\"]\n",
    "             }\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=MLPClassifier(max_iter=1000, random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "  elif estimator == 'gpc':\n",
    "    \n",
    "    param_grid = {\"max_iter_predict\":[100,200,300,400,500,600,700,800,900,1000]}\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=GaussianProcessClassifier(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "    \n",
    "  elif estimator == 'rbfsvm':\n",
    "\n",
    "    param_grid = {'C': [.5,1,10,50,100],\n",
    "            \"class_weight\": [\"balanced\", None]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "\n",
    "    \n",
    "  elif estimator == 'nb':\n",
    "\n",
    "    param_grid = {'var_smoothing': [0.000000001, 0.0000001, 0.00001, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007,\n",
    "                                    0.008, 0.009, 0.01, 0.1, 1]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GaussianNB(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'svm':\n",
    "   \n",
    "    param_grid = {'penalty': ['l2', 'l1','elasticnet'],\n",
    "                  'l1_ratio': [0,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.0002, 0.002, 0.02, 0.0005, 0.005, 0.05],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'eta0': [0.001, 0.01,0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SGDClassifier(loss='hinge', random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "\n",
    "  elif estimator == 'ridge':\n",
    "\n",
    "    param_grid = {'alpha': [0.0001,0.001,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'normalize': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RidgeClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "   \n",
    "  elif estimator == 'rf':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "   \n",
    "  elif estimator == 'ada':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'algorithm' : [\"SAMME\", \"SAMME.R\"]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=AdaBoostClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "\n",
    "  elif estimator == 'gbc':\n",
    "\n",
    "    param_grid = {'loss': ['deviance', 'exponential'],\n",
    "                  'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'subsample' : [0.1,0.3,0.5,0.7,0.9,1],\n",
    "                  'min_samples_split' : [2,4,5,7,9,10],\n",
    "                  'min_samples_leaf' : [1,2,3,4,5],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2']\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GradientBoostingClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "\n",
    "  elif estimator == 'qda':\n",
    "\n",
    "    param_grid = {'reg_param': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=QuadraticDiscriminantAnalysis(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_      \n",
    "\n",
    "  elif estimator == 'lda':\n",
    "\n",
    "    param_grid = {'solver' : ['lsqr', 'eigen'],\n",
    "                  'shrinkage': [0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'et':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=ExtraTreesClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_          \n",
    "    \n",
    "  if estimator == 'dt' and ensemble == True and method == 'Bagging':\n",
    "    \n",
    "    #when using normal BaggingClassifier() DT estimator raise's an exception for max_features parameter. Hence a separate \n",
    "    #call has been made for estimator='dt' and method = 'Bagging' where max_features has been removed from param_grid_dt.\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "    \n",
    "    param_grid_dt = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "                  \"min_samples_leaf\": [2,3,4],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=seed), param_distributions=param_grid_dt,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "    best_model = BaggingClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "  elif ensemble and method == 'Bagging':\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 #'max_features':[1,2,3,5,6,8,10],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "\n",
    "    best_model = BaggingClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "      \n",
    "  elif ensemble and method =='Boosting':\n",
    "        \n",
    "    param_grid = {'n_estimators': [25,35,50,60,70,75],\n",
    "                 'learning_rate': [1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2],\n",
    "                 }        \n",
    "    \n",
    "    best_model = AdaBoostClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    "\n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "    if estimator == 'svm' or estimator == 'ridge':  \n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.00\n",
    "        pred_prob = 0.00\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.00\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa) \n",
    "\n",
    "    else:\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "       \n",
    "  tune_model_ = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  tune_model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  tune_model_ = tune_model_.append(tune_model_avgs)\n",
    "  tune_model_ = tune_model_.round(round)\n",
    "\n",
    "  display(tune_model_)\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models(fold=10, round=4, sort='Accuracy'):\n",
    "  \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "    \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "  kf = StratifiedKFold(fold)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  #avgs_auc =np.empty((0,0))\n",
    "  #avgs_acc =np.empty((0,0))\n",
    "  #avgs_recall =np.empty((0,0))\n",
    "  #avgs_precision =np.empty((0,0))\n",
    "  #avgs_f1 =np.empty((0,0))\n",
    "  #avgs_kappa =np.empty((0,0))\n",
    "  avg_acc = np.empty((0,0))\n",
    "  avg_auc = np.empty((0,0))\n",
    "  avg_recall = np.empty((0,0))\n",
    "  avg_precision = np.empty((0,0))\n",
    "  avg_f1 = np.empty((0,0))\n",
    "  avg_kappa = np.empty((0,0))\n",
    "  \n",
    "  lr = LogisticRegression()\n",
    "  knn = KNeighborsClassifier()\n",
    "  nb = GaussianNB()\n",
    "  dt = DecisionTreeClassifier()\n",
    "  svm = SVC(probability=True,kernel='linear')\n",
    "  rbfsvm = SVC(gamma='auto', C=1, probability=True, kernel='rbf')\n",
    "  gpc = GaussianProcessClassifier()\n",
    "  mlp = MLPClassifier(max_iter=500)\n",
    "  \n",
    "  #comb = [('lr',lr),('knn', knn),('nb', nb)]\n",
    "  comb = [[('lr',lr),('knn', knn),('nb', nb), ('dt', dt), ('svm', svm), ('rbfsvm', rbfsvm), ('gpc', gpc)],\n",
    "          [('lr',lr),('knn', knn),('nb', nb), ('dt', dt), ('svm', svm), ('rbfsvm', rbfsvm), ('mlp', mlp)],\n",
    "          [('lr',lr),('knn', knn),('nb', nb), ('dt', dt), ('svm', svm), ('gpc', gpc), ('mlp', mlp)],\n",
    "          [('lr',lr),('knn', knn),('nb', nb), ('dt', dt), ('rbfsvm', rbfsvm), ('gpc', gpc), ('mlp', mlp)],\n",
    "          [('lr',lr),('knn', knn),('nb', nb), ('svm', svm), ('rbfsvm', rbfsvm), ('gpc', gpc), ('mlp', mlp)],\n",
    "          [('lr',lr),('knn', knn),('dt', dt), ('svm', svm), ('rbfsvm', rbfsvm), ('gpc', gpc), ('mlp', mlp)],\n",
    "          [('lr',lr),('nb', nb),('dt', dt), ('svm', svm), ('rbfsvm', rbfsvm), ('gpc', gpc), ('mlp', mlp)],\n",
    "          [('knn',knn),('nb', nb),('dt', dt), ('svm', svm), ('rbfsvm', rbfsvm), ('gpc', gpc), ('mlp', mlp)]]\n",
    "    \n",
    "  for i in comb:\n",
    "    model = VotingClassifier(estimators=i, voting='soft', n_jobs=-1)\n",
    "  \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.average_precision_score(ytest,pred_prob)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        #score_acc_running = np.append(score_acc_running,sca)\n",
    "    avg_acc = np.append(avg_acc,np.mean(score_acc))\n",
    "    avg_auc = np.append(avg_auc,np.mean(score_auc))\n",
    "    avg_recall = np.append(avg_recall,np.mean(score_recall))\n",
    "    avg_precision = np.append(avg_precision,np.mean(score_precision))\n",
    "    avg_f1 = np.append(avg_f1,np.mean(score_f1))\n",
    "    avg_kappa = np.append(avg_kappa,np.mean(score_kappa))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "  \n",
    "  model_list = ['LR + KNN + NB + DT + SVM + SVM-RBF + GPC', \n",
    "                'LR + KNN + NB + DT + SVM + SVM-RBF + MLP', \n",
    "                'LR + KNN + NB + DT + SVM + GPC + MLP',\n",
    "                'LR + KNN + NB + DT + SVM-RBF + GPC + MLP',\n",
    "                'LR + KNN + NB + SVM + SVM-RBF + GPC + MLP',\n",
    "                'LR + KNN + DT + SVM + SVM-RBF + GPC + MLP',                \n",
    "                'LR + NB + DT + SVM + SVM-RBF + GPC + MLP',                \n",
    "                'KNN + NB + DT + SVM + SVM-RBF + GPC + MLP']\n",
    "                      \n",
    "  #model_list_short = ['LR', 'KNN', 'NB', 'DT', 'SVM-L', 'SVM-RBF','GPC', 'NN-MLP']    \n",
    "  #model_list_repeat = np.repeat(model_list_short, fold)\n",
    "\n",
    "  #compare_models_unpivot = pd.DataFrame({'Model': model_list_repeat, 'Accuracy':score_acc_running}) #accuracy hardcoded\n",
    "  \n",
    "  global blend_models_\n",
    "  \n",
    "  def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "  blend_models_ = pd.DataFrame({'Model':model_list, 'Accuracy':avg_acc, 'AUC':avg_auc, 'Recall':avg_recall, 'Precision':avg_precision, 'F1':avg_f1, 'Kappa': avg_kappa}).round(round).sort_values(by=[sort], ascending=False).reset_index(drop=True).style.apply(highlight_max,subset=['Accuracy','AUC','Recall','Precision','F1','Kappa'])\n",
    "  blend_models_ = blend_models_.set_properties(**{'text-align': 'left'})\n",
    "  blend_models_ = blend_models_.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "\n",
    "  display(blend_models_)\n",
    "    #sns.set(rc={'figure.figsize':(8.7,5.27)})\n",
    "    #sns.boxplot(x='Model', y='Accuracy', data=compare_models_unpivot, width=0.5, linewidth=1, palette='Set2').set_title('Models Accuracy Comparison on Cross Validation') \n",
    "    #accuracy hardcdoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_models(estimator_list, meta_model = None, round = 4, fold = 10, method = 'soft', restack=False, plot=False):\n",
    "    \n",
    "    #Capturing the method of stacking required by user. method='soft' means 'predict_proba' else 'predict'\n",
    "    \n",
    "    if method == 'soft':\n",
    "        predict_method = 'predict_proba'\n",
    "    elif method == 'hard':\n",
    "        predict_method = 'predict'\n",
    "    \n",
    "    #Defining meta model. Logistic Regression hardcoded for now\n",
    "    \n",
    "    if meta_model == None:\n",
    "        meta_model = LogisticRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    global meta_model__ #just for testing\n",
    "    meta_model__ = meta_model\n",
    "    \n",
    "    #defining model_library model names\n",
    "    global model_names\n",
    "    model_names = np.zeros(0)\n",
    "    for item in estimator_list:\n",
    "        model_names = np.append(model_names, str(item).split(\"(\")[0])\n",
    "    \n",
    "    ##########################\n",
    "    ##########################\n",
    "    ##########################\n",
    "    \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in estimator_list:\n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold, method=predict_method)\n",
    "        if method == 'soft':\n",
    "            base_array = base_array[:,1]\n",
    "        elif method == 'hard':\n",
    "            base_array = base_array\n",
    "        base_array_df = pd.DataFrame(base_array)\n",
    "        base_prediction = pd.concat([base_prediction,base_array_df],axis=1)\n",
    "        base_array = np.empty((0,0))\n",
    "        \n",
    "    #defining column names now\n",
    "    target_col_name = np.array(base_prediction.columns[0])\n",
    "    model_names = np.append(target_col_name, model_names)\n",
    "    base_prediction.columns = model_names #defining colum names now\n",
    "    \n",
    "    #defining data_X and data_y dataframe to be used in next stage.\n",
    "    \n",
    "    if restack:\n",
    "        data_X_ = X_train\n",
    "        data_X_ = data_X_.reset_index(drop=True)\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        data_X = pd.concat([data_X_,data_X],axis=1)\n",
    "        \n",
    "    elif restack == False:\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        \n",
    "    data_y = base_prediction[base_prediction.columns[0]]\n",
    "    \n",
    "    #Correlation matrix of base_prediction\n",
    "    global base_prediction_cor\n",
    "    base_prediction_cor = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "    base_prediction_cor = base_prediction_cor.corr()\n",
    "    \n",
    "    #Meta Modeling Starts Here\n",
    "    \n",
    "    model = meta_model #this defines model to be used below as model = meta_model (as captured above)\n",
    "\n",
    "    kf = StratifiedKFold(fold, random_state=seed) #capturing fold requested by user\n",
    "\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.average_precision_score(ytest,pred_prob)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "     \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "    \n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "  \n",
    "    global meta_model_\n",
    "      \n",
    "    meta_model_ = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    meta_model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "    meta_model_ = meta_model_.append(meta_model_avgs)\n",
    "    meta_model_ = meta_model_.round(round)  \n",
    "    \n",
    "    if plot:\n",
    "        ax = sns.heatmap(base_prediction_cor, vmin=-0.5, vmax=1, center=0,cmap='magma', square=True, annot=True, \n",
    "                         linewidths=1)\n",
    "    else:\n",
    "        return meta_model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Starts Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup(data_dummy,'Purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with default hyperparameters. You cannot leave estimator = NULL anymore. \n",
    "create_model(estimator='lr',round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression with Bagging Ensemble. method = 'Bagging' used by default\n",
    "create_model(estimator='lr', ensemble=True, round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression with Boosting Ensemble\n",
    "create_model(estimator='lr', ensemble=True, method='Boosting', round=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 create_model plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check some cool plots\n",
    "create_model(estimator='lr', plot='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr', plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr', plot='pr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr',plot='threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr',plot='learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='dt', plot='vc') #doesn't run on custom models. Only available for DT now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr', plot='dimension') #Doesn't matter which model you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr', plot='manifold') #Doesn't matter which model you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr',plot='boundary') #deprecation warning to be turned off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr', plot='class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr',plot='rfe') #takes some time in generating the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr',plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(estimator='lr', plot='calibration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. compare_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check all the models without tuning and without ensembling\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. tune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's tune Logistic Regression with ensembling (Bagging)\n",
    "tuned_lr = tune_model(estimator='lr', ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's tune Logistic Regression without ensembling\n",
    "tuned_mlp = tune_model(estimator='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_svm = tune_model(estimator='svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's tune decision tree with ensembling (Boosting)\n",
    "tuned_dt = tune_model(estimator='dt', ensemble=True, method='Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_knn = tune_model(estimator='knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_rbfsvm = tune_model(estimator='rbfsvm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. stack_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model library from tuned models\n",
    "model_lib = [tuned_lr, tuned_mlp, tuned_svm, tune_knn, tune_rbfsvm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack tuned models without restacking\n",
    "stack_models(model_lib, tuned_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack tuned models plot\n",
    "stack_models(model_lib, tuned_dt, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
