{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pd_pi\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.pipeline import Pipeline as pipe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORANGE JUICE DATA\n",
    "###################\n",
    "data = pd.read_csv('OJ.csv')\n",
    "data = data.drop(columns='Id')\n",
    "data['Purchase'] = data['Purchase'].replace(['CH','MM'],[1,0])\n",
    "data['Store7'] = data['Store7'].replace(['Yes','No'],[1,0])\n",
    "data = data.drop('STORE',axis = 1)\n",
    "data_dummy = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADULT INCOME DATA (SAMPLE FROM AZURE ML)\n",
    "###################\n",
    "#data = pd.read_csv('adult.csv')\n",
    "#X = data.iloc[:,0:13]\n",
    "#X = X.drop(' education', axis=1)\n",
    "#y = data.iloc[:,-1]\n",
    "#X_dummy = pd.get_dummies(X)\n",
    "#y = y.replace([' >50K',' <=50K'],[1,0])\n",
    "#data_dummy = pd.concat([X_dummy,y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(data, \n",
    "          target, \n",
    "          split=0.7):\n",
    "    \n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X = data.drop(target,axis=1)\n",
    "  y = data[target]\n",
    "  global X_train, X_test, y_train, y_test, seed\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split)\n",
    "  import random\n",
    "  seed = random.randint(150,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(data_dummy, 'Purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(estimator = None, \n",
    "                 ensemble = False, \n",
    "                 method = 'Bagging', \n",
    "                 fold = 10, \n",
    "                 round = 4,  \n",
    "                 verbose = True):\n",
    "  \n",
    "  #defining X_train and y_train    \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "  \n",
    "  #ignore co-linearity warnings for qda and lda \n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "  \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.svm import LinearSVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold  \n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from yellowbrick.classifier import roc_auc\n",
    "  from yellowbrick.classifier import ROCAUC\n",
    "  from yellowbrick.classifier import discrimination_threshold\n",
    "  from yellowbrick.classifier import precision_recall_curve\n",
    "  from yellowbrick.classifier import confusion_matrix\n",
    "  from yellowbrick.classifier import class_prediction_error\n",
    "  from yellowbrick.classifier import classification_report\n",
    "    \n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "  if estimator == None:\n",
    "    print(\"Please enter your custom model as on object or choose from model library. If you have previously defined the estimator, the output is generated using the same estimator\") \n",
    "  elif estimator == 'lr':\n",
    "    model = LogisticRegression(random_state=seed)\n",
    "    full_name = 'Logistic Regression'\n",
    "  elif estimator == 'knn':\n",
    "    model = KNeighborsClassifier()\n",
    "    full_name = 'K Nearest Neighbours'\n",
    "  elif estimator == 'nb':\n",
    "    model = GaussianNB()\n",
    "    full_name = 'Naive Bayes'\n",
    "  elif estimator == 'dt':\n",
    "    model = DecisionTreeClassifier(random_state=seed)\n",
    "    full_name = 'Decision Tree'\n",
    "  elif estimator == 'svm':\n",
    "    model = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "    full_name = 'Support Vector Machine'\n",
    "  elif estimator == 'rbfsvm':\n",
    "    model = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "    full_name = 'RBF SVM'\n",
    "  elif estimator == 'gpc':\n",
    "    model = GaussianProcessClassifier(random_state=seed)\n",
    "    full_name = 'Gaussian Process Classifier'\n",
    "  elif estimator == 'mlp':\n",
    "    model = MLPClassifier(max_iter=500, random_state=seed)\n",
    "    full_name = 'Multi Level Perceptron'    \n",
    "  elif estimator == 'ridge':\n",
    "    model = RidgeClassifier(random_state=seed)\n",
    "    full_name = 'Ridge Classifier'        \n",
    "  elif estimator == 'rf':\n",
    "    model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "    full_name = 'Random Forest Classifier'    \n",
    "  elif estimator == 'qda':\n",
    "    model = QuadraticDiscriminantAnalysis()\n",
    "    full_name = 'Quadratic Discriminant Analysis'    \n",
    "  elif estimator == 'ada':\n",
    "    model = AdaBoostClassifier(random_state=seed)\n",
    "    full_name = 'AdaBoost Classifier'        \n",
    "  elif estimator == 'gbc':\n",
    "    model = GradientBoostingClassifier(random_state=seed)\n",
    "    full_name = 'Gradient Boosting Classifier'          \n",
    "  elif estimator == 'lda':\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    full_name = 'Linear Discriminant Analysis'\n",
    "  elif estimator == 'et':\n",
    "    model = ExtraTreesClassifier(random_state=seed)\n",
    "    full_name = 'Extra Trees Classifier'\n",
    "  else:\n",
    "    model = estimator\n",
    "    full_name = str(model).split(\"(\")[0]\n",
    "  \n",
    "  #checking ensemble method\n",
    "    \n",
    "  if ensemble and method == 'Bagging':\n",
    "    model = BaggingClassifier(model,bootstrap=True,n_estimators=10, random_state=seed)\n",
    "  elif ensemble and method == 'Boosting':\n",
    "    model = AdaBoostClassifier(model, random_state=seed)\n",
    "  elif method == 'Boosting':\n",
    "    model = AdaBoostClassifier(model, random_state=seed)\n",
    "     \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.00\n",
    "        pred_prob = 0.00\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.00\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa) \n",
    "       \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "  model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  model_results_unpivot = pd.melt(model_results,value_vars=['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa'])\n",
    "  model_results_unpivot.columns = ['Metric', 'Measure']\n",
    "  model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)  \n",
    " \n",
    "  if verbose:\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(model_results.to_html()))\n",
    "    return model\n",
    "  else:\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(estimator,\n",
    "                   method = 'Bagging', \n",
    "                   fold = 10,\n",
    "                   n_estimators = 10,\n",
    "                   round = 4,  \n",
    "                   verbose = True):\n",
    "    \n",
    "    #defining X_train and y_train    \n",
    "    data_X = X_train\n",
    "    data_y = y_train\n",
    "  \n",
    "    #ignore co-linearity warnings for qda and lda \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore') \n",
    "    \n",
    "    #defining estimator as model\n",
    "    model = estimator\n",
    "     \n",
    "    if method == 'Bagging':\n",
    "        from sklearn.ensemble import BaggingClassifier\n",
    "        model = BaggingClassifier(model,bootstrap=True,n_estimators=n_estimators, random_state=seed)\n",
    "        \n",
    "    else:\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        model = AdaBoostClassifier(model, random_state=seed)\n",
    "    \n",
    "    kf = StratifiedKFold(fold, random_state=seed)\n",
    "    \n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "            model.fit(Xtrain,ytrain)\n",
    "            pred_prob = model.predict_proba(Xtest)\n",
    "            pred_prob = pred_prob[:,1]\n",
    "            pred_ = model.predict(Xtest)\n",
    "            sca = metrics.accuracy_score(ytest,pred_)\n",
    "            sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "            recall = metrics.recall_score(ytest,pred_)\n",
    "            precision = metrics.precision_score(ytest,pred_)\n",
    "            kappa = cohen_kappa_score(ytest,pred_)\n",
    "            f1 = metrics.f1_score(ytest,pred_)\n",
    "            score_acc = np.append(score_acc,sca)\n",
    "            score_auc = np.append(score_auc,sc)\n",
    "            score_recall = np.append(score_recall,recall)\n",
    "            score_precision = np.append(score_precision,precision)\n",
    "            score_f1 =np.append(score_f1,f1)\n",
    "            score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            model.fit(Xtrain,ytrain)\n",
    "            pred_prob = 0.00\n",
    "            pred_prob = 0.00\n",
    "            pred_ = model.predict(Xtest)\n",
    "            sca = metrics.accuracy_score(ytest,pred_)\n",
    "            sc = 0.00\n",
    "            recall = metrics.recall_score(ytest,pred_)\n",
    "            precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "            kappa = cohen_kappa_score(ytest,pred_)\n",
    "            f1 = metrics.f1_score(ytest,pred_)\n",
    "            score_acc = np.append(score_acc,sca)\n",
    "            score_auc = np.append(score_auc,sc)\n",
    "            score_recall = np.append(score_recall,recall)\n",
    "            score_precision = np.append(score_precision,precision)\n",
    "            score_f1 =np.append(score_f1,f1)\n",
    "            score_kappa =np.append(score_kappa,kappa) \n",
    "       \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "\n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "\n",
    "    model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    model_results_unpivot = pd.melt(model_results,value_vars=['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa'])\n",
    "    model_results_unpivot.columns = ['Metric', 'Measure']\n",
    "    model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "\n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    \n",
    "    model = model\n",
    "    \n",
    "    if verbose:\n",
    "        display(model_results)\n",
    "        return model\n",
    "    else:\n",
    "        return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(estimator, \n",
    "               plot = 'auc', \n",
    "               manifold='tsne',\n",
    "               features=5):\n",
    "    \n",
    "    model = estimator\n",
    "    \n",
    "    if plot == 'auc':\n",
    "        from yellowbrick.classifier import ROCAUC\n",
    "        visualizer = ROCAUC(model)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    elif plot == 'threshold':\n",
    "        from yellowbrick.classifier import DiscriminationThreshold\n",
    "        visualizer = DiscriminationThreshold(model, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "    \n",
    "    elif plot == 'pr':\n",
    "        from yellowbrick.classifier import PrecisionRecallCurve\n",
    "        visualizer = PrecisionRecallCurve(model, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "\n",
    "    elif plot == 'confusion_matrix':\n",
    "        from yellowbrick.classifier import ConfusionMatrix\n",
    "        visualizer = ConfusionMatrix(model, random_state=seed, fontsize=15, cmap=\"Greens\")\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "    \n",
    "    elif plot == 'error':\n",
    "        from yellowbrick.classifier import ClassPredictionError\n",
    "        visualizer = ClassPredictionError(model, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "\n",
    "    elif plot == 'class_report':\n",
    "        from yellowbrick.classifier import ClassificationReport\n",
    "        visualizer = ClassificationReport(model, random_state=seed, support=True)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    elif plot == 'boundary':\n",
    "        \n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "        from yellowbrick.contrib.classifier import DecisionViz        \n",
    "\n",
    "        X_train_transformed = X_train.select_dtypes(include='float64')\n",
    "        X_test_transformed = X_test.select_dtypes(include='float64')\n",
    "        X_train_transformed = StandardScaler().fit_transform(X_train_transformed)\n",
    "        X_test_transformed = StandardScaler().fit_transform(X_test_transformed)\n",
    "        pca = PCA(n_components=2, random_state = seed)\n",
    "        X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "        X_test_transformed = pca.fit_transform(X_test_transformed)\n",
    "\n",
    "        y_train_transformed = np.array(y_train)\n",
    "        y_test_transformed = np.array(y_test)\n",
    "        \n",
    "        model_transformed = model\n",
    "        \n",
    "        viz = DecisionViz(model_transformed)\n",
    "        viz.fit(X_train_transformed, y_train_transformed, features=['Feature One', 'Feature Two'], classes=['A', 'B'])\n",
    "        viz.draw(X_test_transformed, y_test_transformed)\n",
    "        viz.poof()\n",
    "        \n",
    "    elif plot == 'rfe':\n",
    "        from yellowbrick.model_selection import RFECV    \n",
    "        visualizer = RFECV(model, cv=10)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.poof()\n",
    "        \n",
    "        \n",
    "    elif plot == 'learning':\n",
    "        from yellowbrick.model_selection import LearningCurve\n",
    "        sizes = np.linspace(0.3, 1.0, 10)  \n",
    "        visualizer = LearningCurve(model, cv=10, scoring='f1_weighted', train_sizes=sizes, n_jobs=1, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    \n",
    "    elif plot == 'manifold':\n",
    "        from yellowbrick.features import Manifold\n",
    "        X_train_transformed = X_train.select_dtypes(include='float64') \n",
    "        visualizer = Manifold(manifold=manifold, random_state = seed)\n",
    "        visualizer.fit_transform(X_train_transformed, y_train)\n",
    "        visualizer.poof()       \n",
    "        \n",
    "    elif plot == 'calibration':      \n",
    "                \n",
    "        from sklearn.calibration import calibration_curve\n",
    "        \n",
    "        model_name = str(model).split(\"(\")[0]\n",
    "        \n",
    "        plt.figure(figsize=(7, 6))\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "        #model.fit(X_train, y_train)\n",
    "        prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "        prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "        ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % (model_name, ))\n",
    "\n",
    "        ax1.set_ylabel(\"Fraction of positives\")\n",
    "        ax1.set_ylim([0, 1])\n",
    "        ax1.set_xlim([0, 1])\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_title('Calibration plots  (reliability curve)')\n",
    "        ax1.set_facecolor('white')\n",
    "        ax1.grid(b=True, color='grey', linewidth=0.5, linestyle = '-')\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "        \n",
    "    elif plot == 'vc':\n",
    "    \n",
    "        if hasattr(model, 'max_depth'):\n",
    "            param_name='max_depth'\n",
    "        else:\n",
    "            param_name='xxx'\n",
    "       \n",
    "        from yellowbrick.model_selection import ValidationCurve\n",
    "        viz = ValidationCurve(model, param_name=param_name, param_range=np.arange(1,11), scoring='f1_weighted',cv=10, \n",
    "                              random_state=seed)\n",
    "        viz.fit(X_train, y_train)\n",
    "        viz.poof()\n",
    "        \n",
    "    elif plot == 'dimension':\n",
    "    \n",
    "        from yellowbrick.features import RadViz\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        X_train_transformed = X_train.select_dtypes(include='float64') \n",
    "        X_train_transformed = StandardScaler().fit_transform(X_train_transformed)\n",
    "        y_train_transformed = np.array(y_train)\n",
    "\n",
    "        pca = PCA(n_components=features, random_state=seed)\n",
    "        X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "\n",
    "        classes = [\"1\", \"0\"]\n",
    "        visualizer = RadViz(classes=classes, alpha=0.25)\n",
    "        visualizer.fit(X_train_transformed, y_train_transformed)     \n",
    "        visualizer.transform(X_train_transformed)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    elif plot == 'feature':\n",
    "        variables = abs(model.coef_[0])\n",
    "        col_names = np.array(X_train.columns)\n",
    "        coef_df = pd.DataFrame({'Variable': X_train.columns, 'Value': variables})\n",
    "        sorted_df = coef_df.sort_values(by='Value')\n",
    "        my_range=range(1,len(sorted_df.index)+1)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.hlines(y=my_range, xmin=0, xmax=sorted_df['Value'], color='skyblue')\n",
    "        plt.plot(sorted_df['Value'], my_range, \"o\")\n",
    "        plt.yticks(my_range, sorted_df['Variable'])\n",
    "        plt.title(\"Feature Importance Plot\")\n",
    "        plt.xlabel('Variable Importance')\n",
    "        plt.ylabel('Features') \n",
    "        var_imp = sorted_df.reset_index(drop=True)\n",
    "        var_imp_array = np.array(var_imp['Variable'])\n",
    "        var_imp_array_top_n = var_imp_array[0:len(var_imp_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_library = None, \n",
    "                   fold = 10, \n",
    "                   round = 4, \n",
    "                   sort = 'Accuracy', \n",
    "                   blacklist = None):\n",
    "  \n",
    "  #ignore warnings\n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "    \n",
    "  #defining X_train and y_train\n",
    "  data_X = X_train\n",
    "  data_y=y_train\n",
    "\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  import random\n",
    "  import pandas.io.formats.style\n",
    "\n",
    "  lr = LogisticRegression(random_state=seed)\n",
    "  knn = KNeighborsClassifier()\n",
    "  nb = GaussianNB()\n",
    "  dt = DecisionTreeClassifier(random_state=seed)\n",
    "  svm = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "  rbfsvm = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "  gpc = GaussianProcessClassifier(random_state=seed)\n",
    "  mlp = MLPClassifier(max_iter=500, random_state=seed)\n",
    "  ridge = RidgeClassifier(random_state=seed)\n",
    "  rf = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "  qda = QuadraticDiscriminantAnalysis()\n",
    "  ada = AdaBoostClassifier(random_state=seed)\n",
    "  gbc = GradientBoostingClassifier(random_state=seed)\n",
    "  lda = LinearDiscriminantAnalysis()\n",
    "  et = ExtraTreesClassifier(random_state=seed)\n",
    "  \n",
    "  #blacklist models\n",
    "\n",
    "  if model_library != None:\n",
    "    \n",
    "    model_library = model_library\n",
    "    \n",
    "    model_names = []\n",
    "    \n",
    "    for names in model_library:\n",
    "        \n",
    "        model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "        \n",
    "        import re \n",
    "        \n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "            \n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final    \n",
    "    \n",
    "  else:\n",
    "        \n",
    "    if blacklist == None:\n",
    "        \n",
    "        model_library = [lr, knn, nb, dt, svm, rbfsvm, gpc, mlp, ridge, rf, qda, ada, gbc, lda, et]\n",
    "    \n",
    "        model_names = []\n",
    "    \n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "    \n",
    "        import re \n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model_library_values = ['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf', 'qda', \n",
    "                        'ada', 'gbc', 'lda', 'et']\n",
    "\n",
    "        location = []\n",
    "\n",
    "        for item in blacklist:\n",
    "            location.append(model_library_values.index(item))\n",
    "\n",
    "        model_library = [lr, knn, nb, dt, svm, rbfsvm, gpc, mlp, ridge, rf, qda, ada, gbc, lda, et]\n",
    "\n",
    "        for i in location:\n",
    "            del model_library[i]\n",
    "\n",
    "        model_names = []\n",
    "\n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "        import re\n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  score_acc_running = np.empty((0,0)) ##running total\n",
    "  avg_acc = np.empty((0,0))\n",
    "  avg_auc = np.empty((0,0))\n",
    "  avg_recall = np.empty((0,0))\n",
    "  avg_precision = np.empty((0,0))\n",
    "  avg_f1 = np.empty((0,0))\n",
    "  avg_kappa = np.empty((0,0))\n",
    "      \n",
    "  for model in model_library:\n",
    " \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "     \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "          model.fit(Xtrain,ytrain)\n",
    "          pred_prob = model.predict_proba(Xtest)\n",
    "          pred_prob = pred_prob[:,1]\n",
    "          pred_ = model.predict(Xtest)\n",
    "          sca = metrics.accuracy_score(ytest,pred_)\n",
    "          sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "          recall = metrics.recall_score(ytest,pred_)\n",
    "          precision = metrics.precision_score(ytest,pred_)\n",
    "          kappa = cohen_kappa_score(ytest,pred_)\n",
    "          f1 = metrics.f1_score(ytest,pred_)\n",
    "          score_acc = np.append(score_acc,sca)\n",
    "          score_auc = np.append(score_auc,sc)\n",
    "          score_recall = np.append(score_recall,recall)\n",
    "          score_precision = np.append(score_precision,precision)\n",
    "          score_f1 =np.append(score_f1,f1)\n",
    "          score_kappa =np.append(score_kappa,kappa)              \n",
    "        \n",
    "        else:        \n",
    "        \n",
    "          model.fit(Xtrain,ytrain)\n",
    "          pred_prob = 0.00\n",
    "          pred_prob = 0.00\n",
    "          pred_ = model.predict(Xtest)\n",
    "          sca = metrics.accuracy_score(ytest,pred_)\n",
    "          sc = 0.00\n",
    "          recall = metrics.recall_score(ytest,pred_)\n",
    "          precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "          kappa = cohen_kappa_score(ytest,pred_)\n",
    "          f1 = metrics.f1_score(ytest,pred_)\n",
    "          score_acc = np.append(score_acc,sca)\n",
    "          score_auc = np.append(score_auc,sc)\n",
    "          score_recall = np.append(score_recall,recall)\n",
    "          score_precision = np.append(score_precision,precision)\n",
    "          score_f1 =np.append(score_f1,f1)\n",
    "          score_kappa =np.append(score_kappa,kappa) \n",
    "        \n",
    "    avg_acc = np.append(avg_acc,np.mean(score_acc))\n",
    "    avg_auc = np.append(avg_auc,np.mean(score_auc))\n",
    "    avg_recall = np.append(avg_recall,np.mean(score_recall))\n",
    "    avg_precision = np.append(avg_precision,np.mean(score_precision))\n",
    "    avg_f1 = np.append(avg_f1,np.mean(score_f1))\n",
    "    avg_kappa = np.append(avg_kappa,np.mean(score_kappa))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "  \n",
    "  def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "  compare_models_ = pd.DataFrame({'Model':model_names, 'Accuracy':avg_acc, 'AUC':avg_auc, \n",
    "                     'Recall':avg_recall, 'Prec.':avg_precision, \n",
    "                     'F1':avg_f1, 'Kappa': avg_kappa}).round(round).sort_values(by=[sort], \n",
    "                      ascending=False).reset_index(drop=True).style.apply(highlight_max,subset=['Accuracy','AUC','Recall',\n",
    "                      'Prec.','F1','Kappa'])\n",
    "  compare_models_ = compare_models_.set_properties(**{'text-align': 'left'})\n",
    "  compare_models_ = compare_models_.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "                  \n",
    "  return compare_models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(estimator = None, \n",
    "               fold = 10, \n",
    "               round = 4, \n",
    "               n_iter = 10, \n",
    "               optimize = 'accuracy',\n",
    "               ensemble = False, \n",
    "               method = 'Bagging',\n",
    "               verbose = True):\n",
    "   \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold  \n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "    \n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "  if estimator == 'knn':\n",
    "    \n",
    "    param_grid = {'n_neighbors': range(1,51),\n",
    "             'weights' : ['uniform', 'distance'],\n",
    "             'metric':[\"euclidean\", \"manhattan\"]\n",
    "                 }        \n",
    "    model_grid = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=param_grid, \n",
    "                                    scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1, iid=False)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'lr':\n",
    "\n",
    "    param_grid = {'C': [1,5,10,25,50,100],\n",
    "              \"penalty\": [ 'l1', 'l2'],\n",
    "              \"class_weight\": [\"balanced\", None]\n",
    "                 }\n",
    "    model_grid = RandomizedSearchCV(estimator=LogisticRegression(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False,n_jobs=-1)\n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'dt':\n",
    "        \n",
    "    param_grid = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "              \"max_features\": np.random.randint(3, len(X_train.columns),4),\n",
    "              \"min_samples_leaf\": [2,3,4],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'mlp':\n",
    "    \n",
    "    param_grid = {'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "             'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'hidden_layer_sizes': np.random.randint(5,15,5),\n",
    "             'activation': [\"tanh\", \"identity\", \"logistic\",\"relu\"]\n",
    "             }\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=MLPClassifier(max_iter=1000, random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "  elif estimator == 'gpc':\n",
    "    \n",
    "    param_grid = {\"max_iter_predict\":[100,200,300,400,500,600,700,800,900,1000]}\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=GaussianProcessClassifier(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "    \n",
    "  elif estimator == 'rbfsvm':\n",
    "\n",
    "    param_grid = {'C': [.5,1,10,50,100],\n",
    "            \"class_weight\": [\"balanced\", None]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "\n",
    "    \n",
    "  elif estimator == 'nb':\n",
    "\n",
    "    param_grid = {'var_smoothing': [0.000000001, 0.0000001, 0.00001, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007,\n",
    "                                    0.008, 0.009, 0.01, 0.1, 1]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GaussianNB(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'svm':\n",
    "   \n",
    "    param_grid = {'penalty': ['l2', 'l1','elasticnet'],\n",
    "                  'l1_ratio': [0,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.0002, 0.002, 0.02, 0.0005, 0.005, 0.05],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'eta0': [0.001, 0.01,0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SGDClassifier(loss='hinge', random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "\n",
    "  elif estimator == 'ridge':\n",
    "\n",
    "    param_grid = {'alpha': [0.0001,0.001,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'normalize': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RidgeClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "   \n",
    "  elif estimator == 'rf':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "   \n",
    "  elif estimator == 'ada':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'algorithm' : [\"SAMME\", \"SAMME.R\"]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=AdaBoostClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "\n",
    "  elif estimator == 'gbc':\n",
    "\n",
    "    param_grid = {'loss': ['deviance', 'exponential'],\n",
    "                  'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'subsample' : [0.1,0.3,0.5,0.7,0.9,1],\n",
    "                  'min_samples_split' : [2,4,5,7,9,10],\n",
    "                  'min_samples_leaf' : [1,2,3,4,5],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2']\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GradientBoostingClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "\n",
    "  elif estimator == 'qda':\n",
    "\n",
    "    param_grid = {'reg_param': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=QuadraticDiscriminantAnalysis(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_      \n",
    "\n",
    "  elif estimator == 'lda':\n",
    "\n",
    "    param_grid = {'solver' : ['lsqr', 'eigen'],\n",
    "                  'shrinkage': [0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'et':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=ExtraTreesClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_          \n",
    "    \n",
    "  if estimator == 'dt' and ensemble == True and method == 'Bagging':\n",
    "    \n",
    "    #when using normal BaggingClassifier() DT estimator raise's an exception for max_features parameter. Hence a separate \n",
    "    #call has been made for estimator='dt' and method = 'Bagging' where max_features has been removed from param_grid_dt.\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "    \n",
    "    param_grid_dt = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "                  \"min_samples_leaf\": [2,3,4],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=seed), param_distributions=param_grid_dt,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "    best_model = BaggingClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "  elif ensemble and method == 'Bagging':\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "\n",
    "    best_model = BaggingClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "      \n",
    "  elif ensemble and method =='Boosting':\n",
    "        \n",
    "    param_grid = {'n_estimators': [25,35,50,60,70,75],\n",
    "                 'learning_rate': [1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2],\n",
    "                 }        \n",
    "    \n",
    "    best_model = AdaBoostClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    "\n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "    if hasattr(best_model, 'predict_proba'):  \n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.00\n",
    "        pred_prob = 0.00\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.00\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa) \n",
    "        \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "       \n",
    "  model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)\n",
    "  \n",
    "  if verbose:\n",
    "    display(model_results)\n",
    "    return best_model\n",
    "  else:\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models(estimator_list = None, \n",
    "                 fold = 10, \n",
    "                 round = 4, \n",
    "                 sort = 'Accuracy',\n",
    "                 method = 'soft'):\n",
    "  \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "    \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "  avg_acc = np.empty((0,0))\n",
    "  avg_auc = np.empty((0,0))\n",
    "  avg_recall = np.empty((0,0))\n",
    "  avg_precision = np.empty((0,0))\n",
    "  avg_f1 = np.empty((0,0))\n",
    "  avg_kappa = np.empty((0,0))\n",
    "  \n",
    "    \n",
    "  lr = LogisticRegression(random_state=seed)\n",
    "  knn = KNeighborsClassifier()\n",
    "  nb = GaussianNB()\n",
    "  dt = DecisionTreeClassifier(random_state=seed)\n",
    "  svm = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "  rbfsvm = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "  gpc = GaussianProcessClassifier(random_state=seed)\n",
    "  mlp = MLPClassifier(max_iter=500, random_state=seed)\n",
    "  ridge = RidgeClassifier(random_state=seed)\n",
    "  rf = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "  qda = QuadraticDiscriminantAnalysis()\n",
    "  ada = AdaBoostClassifier(random_state=seed)\n",
    "  gbc = GradientBoostingClassifier(random_state=seed)\n",
    "  lda = LinearDiscriminantAnalysis()\n",
    "  et = ExtraTreesClassifier(random_state=seed)  \n",
    "    \n",
    "    \n",
    "  if estimator_list == None:\n",
    "    estimator_list = [lr,knn,nb,dt,svm,rbfsvm,gpc,mlp,ridge,rf,qda,ada,gbc,lda,et]\n",
    "    voting = 'hard'\n",
    "\n",
    "  else:\n",
    "    estimator_list = estimator_list\n",
    "    voting = method  \n",
    "      \n",
    "  model_names = []\n",
    "\n",
    "  for names in estimator_list:\n",
    "    model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "  import re\n",
    "\n",
    "  def putSpace(input):\n",
    "        words = re.findall('[A-Z][a-z]*', input)\n",
    "        words = ' '.join(words)\n",
    "        return words  \n",
    "\n",
    "  model_names_modified = []\n",
    "  \n",
    "  for i in model_names:\n",
    "    model_names_modified.append(putSpace(i))\n",
    "\n",
    "    model_names = model_names_modified\n",
    "\n",
    "  model_names_final = []\n",
    "  \n",
    "  for j in model_names:\n",
    "    if j == 'Gaussian N B':\n",
    "        model_names_final.append('Naive Bayes')\n",
    "    elif j == 'M L P Classifier':\n",
    "        model_names_final.append('MLP Classifier')\n",
    "    elif j == 'S G D Classifier':\n",
    "        model_names_final.append('SVM - Linear Kernel')\n",
    "    elif j == 'S V C':\n",
    "        model_names_final.append('SVM - Radial Kernel')\n",
    "    else: \n",
    "        model_names_final.append(j)\n",
    "\n",
    "  model_names = model_names_final\n",
    "  estimator_list = estimator_list\n",
    "  estimator_list = zip(model_names, estimator_list)\n",
    "  estimator_list = set(estimator_list)\n",
    "  estimator_list = list(estimator_list)\n",
    "    \n",
    "  model = VotingClassifier(estimators=estimator_list, voting=voting, n_jobs=-1)\n",
    "  \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]    \n",
    "    \n",
    "    if voting == 'hard':\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.0\n",
    "        pred_prob = 0.0\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.0\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "       \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "  model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)\n",
    "  display(model_results)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_models(estimator_list, \n",
    "                 meta_model = None, \n",
    "                 fold = 10,\n",
    "                 round = 4, \n",
    "                 method = 'soft', \n",
    "                 restack = False, \n",
    "                 plot = False):\n",
    "    \n",
    "    #Capturing the method of stacking required by user. method='soft' means 'predict_proba' else 'predict'\n",
    "    \n",
    "    if method == 'soft':\n",
    "        predict_method = 'predict_proba'\n",
    "    elif method == 'hard':\n",
    "        predict_method = 'predict'\n",
    "    \n",
    "    #Defining meta model. Logistic Regression hardcoded for now\n",
    "    \n",
    "    if meta_model == None:\n",
    "        meta_model = LogisticRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    #defining model_library model names\n",
    "    \n",
    "    model_names = np.zeros(0)\n",
    "    for item in estimator_list:\n",
    "        model_names = np.append(model_names, str(item).split(\"(\")[0])\n",
    "    \n",
    "    ##########################\n",
    "    ##########################\n",
    "    ##########################\n",
    "    \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in estimator_list:\n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold, method=predict_method)\n",
    "        if method == 'soft':\n",
    "            base_array = base_array[:,1]\n",
    "        elif method == 'hard':\n",
    "            base_array = base_array\n",
    "        base_array_df = pd.DataFrame(base_array)\n",
    "        base_prediction = pd.concat([base_prediction,base_array_df],axis=1)\n",
    "        base_array = np.empty((0,0))\n",
    "        \n",
    "    #defining column names now\n",
    "    target_col_name = np.array(base_prediction.columns[0])\n",
    "    model_names = np.append(target_col_name, model_names)\n",
    "    base_prediction.columns = model_names #defining colum names now\n",
    "    \n",
    "    #defining data_X and data_y dataframe to be used in next stage.\n",
    "    \n",
    "    if restack:\n",
    "        data_X_ = X_train\n",
    "        data_X_ = data_X_.reset_index(drop=True)\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        data_X = pd.concat([data_X_,data_X],axis=1)\n",
    "        \n",
    "    elif restack == False:\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        \n",
    "    data_y = base_prediction[base_prediction.columns[0]]\n",
    "    \n",
    "    #Correlation matrix of base_prediction\n",
    "    base_prediction_cor = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "    base_prediction_cor = base_prediction_cor.corr()\n",
    "    \n",
    "    #Meta Modeling Starts Here\n",
    "    \n",
    "    model = meta_model #this defines model to be used below as model = meta_model (as captured above)\n",
    "\n",
    "    kf = StratifiedKFold(fold, random_state=seed) #capturing fold requested by user\n",
    "\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.average_precision_score(ytest,pred_prob)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "     \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "    \n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "    model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    \n",
    "    models = []\n",
    "    for i in estimator_list:\n",
    "        models.append(i)\n",
    "    \n",
    "    models.append(meta_model)\n",
    "    \n",
    "    if plot:\n",
    "        ax = sns.heatmap(base_prediction_cor, vmin=-0.5, vmax=1, center=0,cmap='magma', square=True, annot=True, \n",
    "                         linewidths=1)\n",
    "    \n",
    "    else:\n",
    "        display(model_results)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacknet(estimator_list,\n",
    "                    meta_model = None,\n",
    "                    fold = 10,\n",
    "                    round = 4,\n",
    "                    method = 'soft',\n",
    "                    restack = False):\n",
    "    \n",
    "    global base_array_df\n",
    "    \n",
    "    base_level = estimator_list[0]\n",
    "    inter_level = estimator_list[1:]\n",
    "    data_X = X_train\n",
    "    data_y = y_train\n",
    "    \n",
    "    #defining meta model\n",
    "    \n",
    "    if meta_model == None:\n",
    "        meta_model = LogisticRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    #Capturing the method of stacking required by user. method='soft' means 'predict_proba' else 'predict'\n",
    "    \n",
    "    if method == 'soft':\n",
    "        predict_method = 'predict_proba'\n",
    "    elif method == 'hard':\n",
    "        predict_method = 'predict'\n",
    "        \n",
    "        \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_array_df = pd.DataFrame()\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in base_level:\n",
    "                     \n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold, method=predict_method)\n",
    "        if method == 'soft':\n",
    "            base_array = base_array[:,1]\n",
    "        elif method == 'hard':\n",
    "            base_array = base_array\n",
    "        base_array = pd.DataFrame(base_array)\n",
    "        base_array_df = pd.concat([base_array_df, base_array], axis=1)\n",
    "        base_array = np.empty((0,0))  \n",
    "        \n",
    "    for level in inter_level:\n",
    "        \n",
    "        for model in level:\n",
    "            \n",
    "            base_array = cross_val_predict(model,base_array_df,base_prediction,cv=fold, method=predict_method)\n",
    "            if method == 'soft':\n",
    "                base_array = base_array[:,1]\n",
    "            elif method == 'hard':\n",
    "                base_array = base_array\n",
    "            base_array = pd.DataFrame(base_array)\n",
    "            base_array_df = pd.concat([base_array, base_array_df], axis=1)\n",
    "            base_array = np.empty((0,0))\n",
    "        \n",
    "        if restack == False:\n",
    "            base_array_df = base_array_df.iloc[:,:len(level)]\n",
    "        else:\n",
    "            base_array_df = base_array_df\n",
    "    \n",
    "    model = meta_model\n",
    "    \n",
    "    kf = StratifiedKFold(fold, random_state=seed) #capturing fold requested by user\n",
    "\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.average_precision_score(ytest,pred_prob)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "     \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "    \n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "    model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)      \n",
    "    \n",
    "    display(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in Progress / Future Release "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(data_X=X_train, n=3):\n",
    "    global X_train\n",
    "    drop_list = var_imp_array_top_n[0:n]\n",
    "    X_train.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules now Available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. plot_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. tune_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0. ensemble_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 blend_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0. stack_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0. create_stacknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0. optimze_model (Future Release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0. predict_stacknet (Future Release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.0. calibrate_model (Future Release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.0. save_model (Future Release) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
