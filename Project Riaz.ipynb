{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOSTON HOUSING DATA\n",
    "###################\n",
    "data = pd.read_csv('Boston.csv')\n",
    "data = data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(data, \n",
    "          target, \n",
    "          split=0.7):\n",
    "    \n",
    "  from sklearn.model_selection import train_test_split\n",
    "  global X_train, X_test, y_train, y_test, X, y, seed\n",
    "  X = data.drop(target,axis=1)\n",
    "  y = data[target]\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split)\n",
    "  import random\n",
    "  seed = random.randint(150,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(data, 'TSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(estimator = None, \n",
    "                 fold = 10, \n",
    "                 round = 4,  \n",
    "                 verbose = True):\n",
    "  \n",
    "  #defining X_train and y_train    \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "  \n",
    "  #ignore co-linearity warnings for qda and lda \n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "  \n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import KFold\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  from sklearn.metrics import mean_squared_log_error\n",
    "  from sklearn.metrics import max_error\n",
    "  from sklearn.metrics import r2_score\n",
    "    \n",
    "  kf = KFold(fold, random_state=seed)\n",
    "\n",
    "  score_mae =np.empty((0,0))\n",
    "  score_mse =np.empty((0,0))\n",
    "  score_rmse =np.empty((0,0))\n",
    "  score_r2 =np.empty((0,0))\n",
    "  score_max_error =np.empty((0,0))\n",
    "  avgs_mae =np.empty((0,0))\n",
    "  avgs_mse =np.empty((0,0))\n",
    "  avgs_rmse =np.empty((0,0))\n",
    "  avgs_r2 =np.empty((0,0))\n",
    "  avgs_max_error =np.empty((0,0))\n",
    "    \n",
    "  if estimator == None:\n",
    "    print(\"Please enter your custom model as on object or choose from model library. If you have previously defined the estimator, the output is generated using the same estimator\") \n",
    "  elif estimator == 'lr':\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    full_name = 'Linear Regression'\n",
    "  elif estimator == 'lasso':\n",
    "    from sklearn.linear_model import Lasso\n",
    "    model = Lasso(random_state=seed)\n",
    "    full_name = 'Lasso Regression'\n",
    "  elif estimator == 'ridge':\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(random_state=seed)\n",
    "    full_name = 'Ridge Regression'\n",
    "  elif estimator == 'en':\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    model = ElasticNet(random_state=seed)\n",
    "    full_name = 'Elastic Net'\n",
    "  elif estimator == 'lars':\n",
    "    from sklearn.linear_model import Lars\n",
    "    model = Lars()\n",
    "    full_name = 'Least Angle Regression'\n",
    "  elif estimator == 'llars':\n",
    "    from sklearn.linear_model import LassoLars\n",
    "    model = LassoLars()\n",
    "    full_name = 'Lasso Least Angle Regression'\n",
    "  elif estimator == 'omp':\n",
    "    from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "    model = OrthogonalMatchingPursuit()\n",
    "    full_name = 'Orthogonal Matching Pursuit'\n",
    "  elif estimator == 'br':\n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "    model = BayesianRidge()\n",
    "    full_name = 'Bayesian Ridge Regression'    \n",
    "  elif estimator == 'ard':\n",
    "    from sklearn.linear_model import ARDRegression\n",
    "    model = ARDRegression()\n",
    "    full_name = 'Automatic Relevance Determination'        \n",
    "  elif estimator == 'par':\n",
    "    from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "    model = PassiveAggressiveRegressor(random_state=seed)\n",
    "    full_name = 'Passive Aggressive Regressor'    \n",
    "  elif estimator == 'ransac':\n",
    "    from sklearn.linear_model import RANSACRegressor\n",
    "    model = RANSACRegressor(random_state=seed)\n",
    "    full_name = 'Random Sample Consensus'   \n",
    "  elif estimator == 'tr':\n",
    "    from sklearn.linear_model import TheilSenRegressor\n",
    "    model = TheilSenRegressor(random_state=seed)\n",
    "    full_name = 'TheilSen Regressor'     \n",
    "  elif estimator == 'huber':\n",
    "    from sklearn.linear_model import HuberRegressor\n",
    "    model = HuberRegressor()\n",
    "    full_name = 'Huber Regressor'   \n",
    "  elif estimator == 'kr':\n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "    model = KernelRidge()\n",
    "    full_name = 'Kernel Ridge'    \n",
    "  elif estimator == 'svm':\n",
    "    from sklearn.svm import SVR\n",
    "    model = SVR()\n",
    "    full_name = 'Support Vector Regression'          \n",
    "  elif estimator == 'knn':\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    model = KNeighborsRegressor()\n",
    "    full_name = 'Nearest Neighbors Regression'      \n",
    "  elif estimator == 'dt':\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    model = DecisionTreeRegressor(random_state=seed)\n",
    "    full_name = 'Decision Tree Regressor'\n",
    "  elif estimator == 'rf':\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    model = RandomForestRegressor(random_state=seed)\n",
    "    full_name = 'Random Forest Regressor'\n",
    "  elif estimator == 'et':\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    model = ExtraTreesRegressor(random_state=seed)\n",
    "    full_name = 'Extra Trees Regressor'    \n",
    "  elif estimator == 'ada':\n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    model = AdaBoostRegressor(random_state=seed)\n",
    "    full_name = 'AdaBoost Regressor'    \n",
    "  elif estimator == 'gbr':\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    model = GradientBoostingRegressor(random_state=seed)\n",
    "    full_name = 'Gradient Boosting Regressor'       \n",
    "  elif estimator == 'mlp':\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    model = MLPRegressor(random_state=seed)\n",
    "    full_name = 'MLP Regressor'\n",
    "  else:\n",
    "    model = estimator\n",
    "    full_name = str(model).split(\"(\")[0]\n",
    "     \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    pred_ = model.predict(Xtest)\n",
    "    mae = mean_absolute_error(ytest,pred_)\n",
    "    mse = mean_squared_error(ytest,pred_)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(ytest,pred_)\n",
    "    max_error_ = max_error(ytest,pred_)\n",
    "    score_mae = np.append(score_mae,mae)\n",
    "    score_mse = np.append(score_mse,mse)\n",
    "    score_rmse = np.append(score_rmse,rmse)\n",
    "    score_r2 =np.append(score_r2,r2)\n",
    "    score_max_error = np.append(score_max_error,max_error_)\n",
    "       \n",
    "  mean_mae=np.mean(score_mae)\n",
    "  mean_mse=np.mean(score_mse)\n",
    "  mean_rmse=np.mean(score_rmse)\n",
    "  mean_r2=np.mean(score_r2)\n",
    "  mean_max_error=np.mean(score_max_error)\n",
    "  std_mae=np.std(score_mae)\n",
    "  std_mse=np.std(score_mse)\n",
    "  std_rmse=np.std(score_rmse)\n",
    "  std_r2=np.std(score_r2)\n",
    "  std_max_error=np.std(score_max_error)\n",
    "    \n",
    "  avgs_mae = np.append(avgs_mae, mean_mae)\n",
    "  avgs_mae = np.append(avgs_mae, std_mae) \n",
    "  avgs_mse = np.append(avgs_mse, mean_mse)\n",
    "  avgs_mse = np.append(avgs_mse, std_mse)\n",
    "  avgs_rmse = np.append(avgs_rmse, mean_rmse)\n",
    "  avgs_rmse = np.append(avgs_rmse, std_rmse)\n",
    "  avgs_r2 = np.append(avgs_r2, mean_r2)\n",
    "  avgs_r2 = np.append(avgs_r2, std_r2)\n",
    "  avgs_max_error = np.append(avgs_max_error, mean_max_error)\n",
    "  avgs_max_error = np.append(avgs_max_error, std_max_error)\n",
    "    \n",
    "  model_results = pd.DataFrame({'MAE': score_mae, 'MSE': score_mse, 'RMSE' : score_rmse, \n",
    "                                'R2' : score_r2, 'ME' : score_max_error})\n",
    "\n",
    "  model_avgs = pd.DataFrame({'MAE': avgs_mae, 'MSE': avgs_mse, 'RMSE' : avgs_rmse, 'R2' : avgs_r2,\n",
    "                             'ME' : avgs_max_error},index=['Mean', 'SD'])\n",
    "    \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)  \n",
    "  model_results = model_results.style.set_table_styles([ dict(selector='th', props=[('text-align', 'center')] ) ])\n",
    "\n",
    "  if verbose:\n",
    "    display(model_results)\n",
    "    return model\n",
    "  else:\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_library = None, \n",
    "                   fold = 10, \n",
    "                   round = 4, \n",
    "                   sort = 'MAE', \n",
    "                   blacklist = None):\n",
    "  \n",
    "  #ignore warnings\n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "    \n",
    "  #defining X_train and y_train\n",
    "  data_X = X_train\n",
    "  data_y=y_train\n",
    "\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  from sklearn.linear_model import Ridge\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import ElasticNet\n",
    "  from sklearn.linear_model import Lars\n",
    "  from sklearn.linear_model import LassoLars\n",
    "  from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "  from sklearn.linear_model import BayesianRidge\n",
    "  from sklearn.linear_model import ARDRegression\n",
    "  from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "  from sklearn.linear_model import RANSACRegressor\n",
    "  from sklearn.linear_model import TheilSenRegressor\n",
    "  from sklearn.linear_model import HuberRegressor\n",
    "  from sklearn.kernel_ridge import KernelRidge\n",
    "  from sklearn.svm import SVR\n",
    "  from sklearn.neighbors import KNeighborsRegressor\n",
    "  from sklearn.tree import DecisionTreeRegressor\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from sklearn.ensemble import ExtraTreesRegressor\n",
    "  from sklearn.ensemble import AdaBoostRegressor\n",
    "  from sklearn.ensemble import GradientBoostingRegressor\n",
    "  from sklearn.neural_network import MLPRegressor \n",
    "  from sklearn.model_selection import KFold\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.model_selection import KFold\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  from sklearn.metrics import mean_squared_log_error\n",
    "  from sklearn.metrics import max_error\n",
    "  from sklearn.metrics import r2_score\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import random\n",
    "  import pandas.io.formats.style\n",
    "\n",
    "  lr = LinearRegression()\n",
    "  lasso = Lasso(random_state=seed)\n",
    "  ridge = Ridge(random_state=seed)\n",
    "  en = ElasticNet(random_state=seed)\n",
    "  lars = Lars()\n",
    "  llars = LassoLars()\n",
    "  omp = OrthogonalMatchingPursuit()\n",
    "  br = BayesianRidge()\n",
    "  ard = ARDRegression()\n",
    "  par = PassiveAggressiveRegressor(random_state=seed)\n",
    "  ransac = RANSACRegressor(random_state=seed)\n",
    "  tr = TheilSenRegressor(random_state=seed)\n",
    "  huber = HuberRegressor()\n",
    "  kr = KernelRidge()\n",
    "  svr = SVR()\n",
    "  knn = KNeighborsRegressor()\n",
    "  dt = DecisionTreeRegressor(random_state=seed)\n",
    "  rf = RandomForestRegressor(random_state=seed)\n",
    "  et = ExtraTreesRegressor(random_state=seed)\n",
    "  ada = AdaBoostRegressor(random_state=seed)\n",
    "  gbr = GradientBoostingRegressor(random_state=seed)\n",
    "  mlp = MLPRegressor(random_state=seed)  \n",
    "  \n",
    "  #blacklist models\n",
    "\n",
    "  if model_library != None:\n",
    "    \n",
    "    model_library = model_library\n",
    "    \n",
    "    model_names = []\n",
    "    \n",
    "    for names in model_library:\n",
    "        \n",
    "        model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "        \n",
    "        import re \n",
    "        \n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "            \n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'A R D Regression':\n",
    "                model_names_final.append('Automatic Relevance Determination')\n",
    "            elif j == 'M L P Regressor':\n",
    "                model_names_final.append('MLP Regressor')\n",
    "            elif j == 'R A N S A C Regressor':\n",
    "                model_names_final.append('RANSAC Regressor')\n",
    "            elif j == 'S V R':\n",
    "                model_names_final.append('Support Vector Regressor')\n",
    "            elif j == 'Lars':\n",
    "                model_names_final.append('Least Angle Regression')                \n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final    \n",
    "    \n",
    "  else:\n",
    "        \n",
    "    if blacklist == None:\n",
    "        \n",
    "        model_library = [lr, lasso, ridge, en, lars, llars, omp, br, ard, par, ransac, tr, huber, kr, svr, knn, \n",
    "                        dt, rf, et, ada, gbr, mlp]\n",
    "    \n",
    "        model_names = []\n",
    "    \n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "    \n",
    "        import re \n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            \n",
    "            if j == 'A R D Regression':\n",
    "                model_names_final.append('Automatic Relevance Determination')\n",
    "            elif j == 'M L P Regressor':\n",
    "                model_names_final.append('MLP Regressor')\n",
    "            elif j == 'R A N S A C Regressor':\n",
    "                model_names_final.append('RANSAC Regressor')\n",
    "            elif j == 'S V R':\n",
    "                model_names_final.append('Support Vector Regressor')\n",
    "            elif j == 'Lars':\n",
    "                model_names_final.append('Least Angle Regression')  \n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model_library_values = ['lr', 'lasso', 'ridge', 'en', 'lars', 'llars', 'omp', 'br', 'ard', 'par', 'ransac', 'tr',\n",
    "                                'huber', 'kr', 'svr', 'knn', 'dt', 'rf', 'et', 'ada', 'gbr', 'mlp']\n",
    "\n",
    "        location = []\n",
    "\n",
    "        for item in blacklist:\n",
    "            location.append(model_library_values.index(item))\n",
    "\n",
    "        model_library = [lr, lasso, ridge, en, lars, llars, omp, br, ard, par, ransac, tr, huber, kr, svr, knn, \n",
    "                        dt, rf, et, ada, gbr, mlp]\n",
    "\n",
    "        for i in location:\n",
    "            del model_library[i]\n",
    "\n",
    "        model_names = []\n",
    "\n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "        import re\n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "  kf = KFold(fold, random_state=seed)\n",
    "  \n",
    "  score_mae =np.empty((0,0))\n",
    "  score_mse =np.empty((0,0))\n",
    "  score_rmse =np.empty((0,0))\n",
    "  score_r2 =np.empty((0,0))\n",
    "  score_max_error =np.empty((0,0))\n",
    "  #avgs_mae =np.empty((0,0))\n",
    "  #avgs_mse =np.empty((0,0))\n",
    "  #avgs_rmse =np.empty((0,0))\n",
    "  #avgs_r2 =np.empty((0,0))\n",
    "  #avgs_max_error =np.empty((0,0))\n",
    "    \n",
    "  avg_mae = np.empty((0,0))\n",
    "  avg_mse = np.empty((0,0))\n",
    "  avg_rmse = np.empty((0,0))\n",
    "  avg_r2 = np.empty((0,0))\n",
    "  avg_max_error = np.empty((0,0))\n",
    "  #avg_kappa = np.empty((0,0))\n",
    "      \n",
    "  for model in model_library:\n",
    " \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "     \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_ = model.predict(Xtest)\n",
    "        mae = mean_absolute_error(ytest,pred_)\n",
    "        mse = mean_squared_error(ytest,pred_)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(ytest,pred_)\n",
    "        max_error_ = max_error(ytest,pred_)\n",
    "        score_mae = np.append(score_mae,mae)\n",
    "        score_mse = np.append(score_mse,mse)\n",
    "        score_rmse = np.append(score_rmse,rmse)\n",
    "        score_r2 =np.append(score_r2,r2)\n",
    "        score_max_error = np.append(score_max_error,max_error_)\n",
    "        \n",
    "    avg_mae = np.append(avg_mae,np.mean(score_mae))\n",
    "    avg_mse = np.append(avg_mse,np.mean(score_mse))\n",
    "    avg_rmse = np.append(avg_rmse,np.mean(score_rmse))\n",
    "    avg_r2 = np.append(avg_r2,np.mean(score_r2))\n",
    "    avg_max_error = np.append(avg_max_error,np.mean(score_max_error))\n",
    "    \n",
    "    score_mae =np.empty((0,0))\n",
    "    score_mse =np.empty((0,0))\n",
    "    score_rmse =np.empty((0,0))\n",
    "    score_r2 =np.empty((0,0))\n",
    "    score_max_error =np.empty((0,0))\n",
    "    #score_kappa =np.empty((0,0))\n",
    "  \n",
    "  def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_min]\n",
    "\n",
    "  def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "  compare_models_ = pd.DataFrame({'Model':model_names, 'MAE':avg_mae, 'MSE':avg_mse, \n",
    "                     'RMSE':avg_rmse, 'R2':avg_r2, \n",
    "                     'ME':avg_max_error}).round(round).sort_values(by=[sort], \n",
    "                      ascending=True).reset_index(drop=True).style.apply(highlight_min,subset=['MAE','MSE','RMSE','ME']) #.style.apply(highlight_max, subset='R2')\n",
    "  compare_models_ = compare_models_.set_properties(**{'text-align': 'left'})\n",
    "  compare_models_ = compare_models_.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "                  \n",
    "  return compare_models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(estimator,\n",
    "                   method = 'Bagging', \n",
    "                   fold = 10,\n",
    "                   n_estimators = 10,\n",
    "                   round = 4,  \n",
    "                   verbose = True):\n",
    "    \n",
    "    #loading general libraries\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_squared_log_error\n",
    "    from sklearn.metrics import max_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    #defining X_train and y_train    \n",
    "    data_X = X_train\n",
    "    data_y = y_train\n",
    "  \n",
    "    #ignore co-linearity warnings for qda and lda \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore') \n",
    "    \n",
    "    #defining estimator as model\n",
    "    model = estimator\n",
    "     \n",
    "    if method == 'Bagging':\n",
    "        from sklearn.ensemble import BaggingRegressor\n",
    "        model = BaggingRegressor(model,bootstrap=True,n_estimators=n_estimators, random_state=seed)\n",
    "        \n",
    "    else:\n",
    "        from sklearn.ensemble import AdaBoostRegressor\n",
    "        model = AdaBoostRegressor(model, random_state=seed)\n",
    "    \n",
    "    kf = KFold(fold, random_state=seed)\n",
    "    \n",
    "    score_mae =np.empty((0,0))\n",
    "    score_mse =np.empty((0,0))\n",
    "    score_rmse =np.empty((0,0))\n",
    "    score_r2 =np.empty((0,0))\n",
    "    score_max_error =np.empty((0,0))\n",
    "    avgs_mae =np.empty((0,0))\n",
    "    avgs_mse =np.empty((0,0))\n",
    "    avgs_rmse =np.empty((0,0))\n",
    "    avgs_r2 =np.empty((0,0))\n",
    "    avgs_max_error =np.empty((0,0))\n",
    "\n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_ = model.predict(Xtest)\n",
    "        mae = mean_absolute_error(ytest,pred_)\n",
    "        mse = mean_squared_error(ytest,pred_)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(ytest,pred_)\n",
    "        max_error_ = max_error(ytest,pred_)\n",
    "        score_mae = np.append(score_mae,mae)\n",
    "        score_mse = np.append(score_mse,mse)\n",
    "        score_rmse = np.append(score_rmse,rmse)\n",
    "        score_r2 =np.append(score_r2,r2)\n",
    "        score_max_error = np.append(score_max_error,max_error_)\n",
    "\n",
    "    mean_mae=np.mean(score_mae)\n",
    "    mean_mse=np.mean(score_mse)\n",
    "    mean_rmse=np.mean(score_rmse)\n",
    "    mean_r2=np.mean(score_r2)\n",
    "    mean_max_error=np.mean(score_max_error)\n",
    "    std_mae=np.std(score_mae)\n",
    "    std_mse=np.std(score_mse)\n",
    "    std_rmse=np.std(score_rmse)\n",
    "    std_r2=np.std(score_r2)\n",
    "    std_max_error=np.std(score_max_error)\n",
    "\n",
    "    avgs_mae = np.append(avgs_mae, mean_mae)\n",
    "    avgs_mae = np.append(avgs_mae, std_mae) \n",
    "    avgs_mse = np.append(avgs_mse, mean_mse)\n",
    "    avgs_mse = np.append(avgs_mse, std_mse)\n",
    "    avgs_rmse = np.append(avgs_rmse, mean_rmse)\n",
    "    avgs_rmse = np.append(avgs_rmse, std_rmse)\n",
    "    avgs_r2 = np.append(avgs_r2, mean_r2)\n",
    "    avgs_r2 = np.append(avgs_r2, std_r2)\n",
    "    avgs_max_error = np.append(avgs_max_error, mean_max_error)\n",
    "    avgs_max_error = np.append(avgs_max_error, std_max_error)\n",
    "\n",
    "    \n",
    "    \n",
    "    model_results = pd.DataFrame({'MAE': score_mae, 'MSE': score_mse, 'RMSE' : score_rmse, \n",
    "                                    'R2' : score_r2, 'ME' : score_max_error})\n",
    "    model_avgs = pd.DataFrame({'MAE': avgs_mae, 'MSE': avgs_mse, 'RMSE' : avgs_rmse, 'R2' : avgs_r2,\n",
    "                             'ME' : avgs_max_error},index=['Mean', 'SD'])\n",
    "\n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    model_results = model_results.style.set_table_styles([ dict(selector='th', props=[('text-align', 'center')] ) ])\n",
    "    \n",
    "    model = model\n",
    "    \n",
    "    if verbose:\n",
    "        display(model_results)\n",
    "        return model\n",
    "    else:\n",
    "        return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models(estimator_list = None, \n",
    "                 fold = 10, \n",
    "                 round = 4, \n",
    "                 sort = 'mae'):\n",
    "  \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "    \n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  from sklearn import metrics\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  from sklearn.linear_model import Ridge\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import ElasticNet\n",
    "  from sklearn.linear_model import Lars\n",
    "  from sklearn.linear_model import LassoLars\n",
    "  from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "  from sklearn.linear_model import BayesianRidge\n",
    "  from sklearn.linear_model import ARDRegression\n",
    "  from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "  from sklearn.linear_model import RANSACRegressor\n",
    "  from sklearn.linear_model import TheilSenRegressor\n",
    "  from sklearn.linear_model import HuberRegressor\n",
    "  from sklearn.kernel_ridge import KernelRidge\n",
    "  from sklearn.svm import SVR\n",
    "  from sklearn.neighbors import KNeighborsRegressor\n",
    "  from sklearn.tree import DecisionTreeRegressor\n",
    "  from sklearn.ensemble import RandomForestRegressor\n",
    "  from sklearn.ensemble import ExtraTreesRegressor\n",
    "  from sklearn.ensemble import AdaBoostRegressor\n",
    "  from sklearn.ensemble import GradientBoostingRegressor\n",
    "  from sklearn.neural_network import MLPRegressor \n",
    "  from sklearn.ensemble import VotingRegressor\n",
    "  from sklearn.model_selection import KFold\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  from sklearn.metrics import mean_squared_log_error\n",
    "  from sklearn.metrics import max_error\n",
    "  from sklearn.metrics import r2_score\n",
    "\n",
    "  kf = KFold(fold, random_state=seed)\n",
    "\n",
    "  score_mae =np.empty((0,0))\n",
    "  score_mse =np.empty((0,0))\n",
    "  score_rmse =np.empty((0,0))\n",
    "  score_r2 =np.empty((0,0))\n",
    "  score_max_error =np.empty((0,0))\n",
    "  avgs_mae =np.empty((0,0))\n",
    "  avgs_mse =np.empty((0,0))\n",
    "  avgs_rmse =np.empty((0,0))\n",
    "  avgs_r2 =np.empty((0,0))\n",
    "  avgs_max_error =np.empty((0,0))\n",
    " \n",
    "  lr = LinearRegression()\n",
    "  lasso = Lasso(random_state=seed)\n",
    "  ridge = Ridge(random_state=seed)\n",
    "  en = ElasticNet(random_state=seed)\n",
    "  lars = Lars()\n",
    "  llars = LassoLars()\n",
    "  omp = OrthogonalMatchingPursuit()\n",
    "  br = BayesianRidge()\n",
    "  ard = ARDRegression()\n",
    "  par = PassiveAggressiveRegressor(random_state=seed)\n",
    "  ransac = RANSACRegressor(random_state=seed)\n",
    "  tr = TheilSenRegressor(random_state=seed)\n",
    "  huber = HuberRegressor()\n",
    "  kr = KernelRidge()\n",
    "  svr = SVR()\n",
    "  knn = KNeighborsRegressor()\n",
    "  dt = DecisionTreeRegressor(random_state=seed)\n",
    "  rf = RandomForestRegressor(random_state=seed)\n",
    "  et = ExtraTreesRegressor(random_state=seed)\n",
    "  ada = AdaBoostRegressor(random_state=seed)\n",
    "  gbr = GradientBoostingRegressor(random_state=seed)\n",
    "  mlp = MLPRegressor(random_state=seed)  \n",
    "    \n",
    "  if estimator_list == None:\n",
    "    estimator_list = [lr,lasso,ridge,en,lars,llars,omp,br,ard,par,ransac,tr,huber,kr,svr,knn,dt,rf,et,ada,gbr,mlp]\n",
    "\n",
    "  else:\n",
    "    estimator_list = estimator_list\n",
    "\n",
    "  model_names = []\n",
    "\n",
    "  for names in estimator_list:\n",
    "    model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "  import re\n",
    "\n",
    "  def putSpace(input):\n",
    "        words = re.findall('[A-Z][a-z]*', input)\n",
    "        words = ' '.join(words)\n",
    "        return words  \n",
    "\n",
    "  model_names_modified = []\n",
    "  \n",
    "  for i in model_names:\n",
    "    model_names_modified.append(putSpace(i))\n",
    "\n",
    "    model_names = model_names_modified\n",
    "\n",
    "  model_names_final = []\n",
    "  \n",
    "  for j in model_names:\n",
    "\n",
    "    if j == 'A R D Regression':\n",
    "        model_names_final.append('Automatic Relevance Determination')\n",
    "    elif j == 'M L P Regressor':\n",
    "        model_names_final.append('MLP Regressor')\n",
    "    elif j == 'R A N S A C Regressor':\n",
    "        model_names_final.append('RANSAC Regressor')\n",
    "    elif j == 'S V R':\n",
    "        model_names_final.append('Support Vector Regressor')\n",
    "    elif j == 'Lars':\n",
    "        model_names_final.append('Least Angle Regression')                \n",
    "    else: \n",
    "        model_names_final.append(j)\n",
    "        \n",
    "  model_names = model_names_final\n",
    "  estimator_list = estimator_list\n",
    "  estimator_list = zip(model_names, estimator_list)\n",
    "  estimator_list = set(estimator_list)\n",
    "  estimator_list = list(estimator_list)\n",
    "    \n",
    "  model = VotingRegressor(estimators=estimator_list, n_jobs=-1)\n",
    "  \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]    \n",
    "    model.fit(Xtrain,ytrain)\n",
    "    pred_ = model.predict(Xtest)\n",
    "    mae = mean_absolute_error(ytest,pred_)\n",
    "    mse = mean_squared_error(ytest,pred_)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(ytest,pred_)\n",
    "    max_error_ = max_error(ytest,pred_)\n",
    "    score_mae = np.append(score_mae,mae)\n",
    "    score_mse = np.append(score_mse,mse)\n",
    "    score_rmse = np.append(score_rmse,rmse)\n",
    "    score_r2 =np.append(score_r2,r2)\n",
    "    score_max_error = np.append(score_max_error,max_error_)\n",
    "       \n",
    "  mean_mae=np.mean(score_mae)\n",
    "  mean_mse=np.mean(score_mse)\n",
    "  mean_rmse=np.mean(score_rmse)\n",
    "  mean_r2=np.mean(score_r2)\n",
    "  mean_max_error=np.mean(score_max_error)\n",
    "  std_mae=np.std(score_mae)\n",
    "  std_mse=np.std(score_mse)\n",
    "  std_rmse=np.std(score_rmse)\n",
    "  std_r2=np.std(score_r2)\n",
    "  std_max_error=np.std(score_max_error)\n",
    "    \n",
    "  avgs_mae = np.append(avgs_mae, mean_mae)\n",
    "  avgs_mae = np.append(avgs_mae, std_mae) \n",
    "  avgs_mse = np.append(avgs_mse, mean_mse)\n",
    "  avgs_mse = np.append(avgs_mse, std_mse)\n",
    "  avgs_rmse = np.append(avgs_rmse, mean_rmse)\n",
    "  avgs_rmse = np.append(avgs_rmse, std_rmse)\n",
    "  avgs_r2 = np.append(avgs_r2, mean_r2)\n",
    "  avgs_r2 = np.append(avgs_r2, std_r2)\n",
    "  avgs_max_error = np.append(avgs_max_error, mean_max_error)\n",
    "  avgs_max_error = np.append(avgs_max_error, std_max_error)\n",
    "    \n",
    "  model_results = pd.DataFrame({'MAE': score_mae, 'MSE': score_mse, 'RMSE' : score_rmse, \n",
    "                                'R2' : score_r2, 'ME' : score_max_error})\n",
    "  model_avgs = pd.DataFrame({'MAE': avgs_mae, 'MSE': avgs_mse, 'RMSE' : avgs_rmse, 'R2' : avgs_r2,\n",
    "                             'ME' : avgs_max_error},index=['Mean', 'SD'])\n",
    "    \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)  \n",
    "  model_results = model_results.style.set_table_styles([ dict(selector='th', props=[('text-align', 'center')] ) ])\n",
    "  display(model_results)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_models(estimator_list, \n",
    "                 meta_model = None, \n",
    "                 fold = 10,\n",
    "                 round = 4, \n",
    "                 restack = False, \n",
    "                 plot = False):\n",
    "       \n",
    "    #Defining meta model. Linear Regression hardcoded for now\n",
    "    \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_squared_log_error\n",
    "    from sklearn.metrics import max_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    if meta_model == None:\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        meta_model = LinearRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    #defining model_library model names\n",
    "    \n",
    "    model_names = np.zeros(0)\n",
    "    for item in estimator_list:\n",
    "        model_names = np.append(model_names, str(item).split(\"(\")[0])\n",
    "    \n",
    "    ##########################\n",
    "    ##########################\n",
    "    ##########################\n",
    "    \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in estimator_list:\n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold)\n",
    "        base_array = base_array\n",
    "        base_array_df = pd.DataFrame(base_array)\n",
    "        base_prediction = pd.concat([base_prediction,base_array_df],axis=1)\n",
    "        base_array = np.empty((0,0))\n",
    "        \n",
    "    #defining column names now\n",
    "    target_col_name = np.array(base_prediction.columns[0])\n",
    "    model_names = np.append(target_col_name, model_names)\n",
    "    base_prediction.columns = model_names #defining colum names now\n",
    "    \n",
    "    #defining data_X and data_y dataframe to be used in next stage.\n",
    "    \n",
    "    if restack:\n",
    "        data_X_ = X_train\n",
    "        data_X_ = data_X_.reset_index(drop=True)\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        data_X = pd.concat([data_X_,data_X],axis=1)\n",
    "        \n",
    "    elif restack == False:\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        \n",
    "    data_y = base_prediction[base_prediction.columns[0]]\n",
    "    \n",
    "    #Correlation matrix of base_prediction\n",
    "    base_prediction_cor = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "    base_prediction_cor = base_prediction_cor.corr()\n",
    "    \n",
    "    #Meta Modeling Starts Here\n",
    "    \n",
    "    model = meta_model #this defines model to be used below as model = meta_model (as captured above)\n",
    "\n",
    "    kf = KFold(fold, random_state=seed) #capturing fold requested by user\n",
    "    \n",
    "    score_mae =np.empty((0,0))\n",
    "    score_mse =np.empty((0,0))\n",
    "    score_rmse =np.empty((0,0))\n",
    "    score_r2 =np.empty((0,0))\n",
    "    score_max_error =np.empty((0,0))\n",
    "    avgs_mae =np.empty((0,0))\n",
    "    avgs_mse =np.empty((0,0))\n",
    "    avgs_rmse =np.empty((0,0))\n",
    "    avgs_r2 =np.empty((0,0))\n",
    "    avgs_max_error =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_ = model.predict(Xtest)\n",
    "        mae = mean_absolute_error(ytest,pred_)\n",
    "        mse = mean_squared_error(ytest,pred_)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(ytest,pred_)\n",
    "        max_error_ = max_error(ytest,pred_)\n",
    "        score_mae = np.append(score_mae,mae)\n",
    "        score_mse = np.append(score_mse,mse)\n",
    "        score_rmse = np.append(score_rmse,rmse)\n",
    "        score_r2 =np.append(score_r2,r2)\n",
    "        score_max_error = np.append(score_max_error,max_error_)\n",
    "   \n",
    "    mean_mae=np.mean(score_mae)\n",
    "    mean_mse=np.mean(score_mse)\n",
    "    mean_rmse=np.mean(score_rmse)\n",
    "    mean_r2=np.mean(score_r2)\n",
    "    mean_max_error=np.mean(score_max_error)\n",
    "    std_mae=np.std(score_mae)\n",
    "    std_mse=np.std(score_mse)\n",
    "    std_rmse=np.std(score_rmse)\n",
    "    std_r2=np.std(score_r2)\n",
    "    std_max_error=np.std(score_max_error)\n",
    "\n",
    "    avgs_mae = np.append(avgs_mae, mean_mae)\n",
    "    avgs_mae = np.append(avgs_mae, std_mae) \n",
    "    avgs_mse = np.append(avgs_mse, mean_mse)\n",
    "    avgs_mse = np.append(avgs_mse, std_mse)\n",
    "    avgs_rmse = np.append(avgs_rmse, mean_rmse)\n",
    "    avgs_rmse = np.append(avgs_rmse, std_rmse)\n",
    "    avgs_r2 = np.append(avgs_r2, mean_r2)\n",
    "    avgs_r2 = np.append(avgs_r2, std_r2)\n",
    "    avgs_max_error = np.append(avgs_max_error, mean_max_error)\n",
    "    avgs_max_error = np.append(avgs_max_error, std_max_error)\n",
    "           \n",
    "    \n",
    "    model_results = pd.DataFrame({'MAE': score_mae, 'MSE': score_mse, 'RMSE' : score_rmse, \n",
    "                                'R2' : score_r2, 'ME' : score_max_error})\n",
    "\n",
    "    model_avgs = pd.DataFrame({'MAE': avgs_mae, 'MSE': avgs_mse, 'RMSE' : avgs_rmse, 'R2' : avgs_r2,\n",
    "                             'ME' : avgs_max_error},index=['Mean', 'SD'])\n",
    "\n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    model_results = model_results.style.set_table_styles([ dict(selector='th', props=[('text-align', 'center')] ) ])\n",
    "    \n",
    "    models = []\n",
    "    for i in estimator_list:\n",
    "        models.append(i)\n",
    "    \n",
    "    models.append(meta_model)\n",
    "    \n",
    "    if plot:\n",
    "        ax = sns.heatmap(base_prediction_cor, vmin=-0.5, vmax=1, center=0,cmap='magma', square=True, annot=True, \n",
    "                         linewidths=1)\n",
    "    \n",
    "    else:\n",
    "        display(model_results)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(estimator = None, \n",
    "               fold = 10, \n",
    "               round = 4, \n",
    "               n_iter = 10, \n",
    "               optimize = 'mae',\n",
    "               ensemble = False, \n",
    "               method = 'Bagging',\n",
    "               verbose = True):\n",
    "  \n",
    "  #defining data\n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "  \n",
    "  #defining optimizer\n",
    "  if optimize == 'mae':\n",
    "    optimize = 'neg_mean_absolute_error'\n",
    "  elif optimize == 'mse':\n",
    "    optimize = 'neg_mean_squared_error'\n",
    "  elif optimize == 'me':\n",
    "    optimize = 'max_error'\n",
    "  elif optimize == 'r2':\n",
    "    optimize = 'r2'\n",
    "    \n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  from sklearn import metrics\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  from sklearn.metrics import mean_squared_log_error\n",
    "  from sklearn.metrics import max_error\n",
    "  from sklearn.metrics import r2_score\n",
    "  from sklearn.model_selection import KFold\n",
    "    \n",
    "  kf = KFold(fold, random_state=seed)\n",
    "\n",
    "  score_mae =np.empty((0,0))\n",
    "  score_mse =np.empty((0,0))\n",
    "  score_rmse =np.empty((0,0))\n",
    "  score_r2 =np.empty((0,0))\n",
    "  score_max_error =np.empty((0,0))\n",
    "  avgs_mae =np.empty((0,0))\n",
    "  avgs_mse =np.empty((0,0))\n",
    "  avgs_rmse =np.empty((0,0))\n",
    "  avgs_r2 =np.empty((0,0))\n",
    "  avgs_max_error =np.empty((0,0))\n",
    "    \n",
    "  if estimator == 'lr':\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    param_grid = {'fit_intercept': [True, False],\n",
    "             'normalize' : [True, False]\n",
    "                 }        \n",
    "    model_grid = RandomizedSearchCV(estimator=LinearRegression(), param_distributions=param_grid, \n",
    "                                    scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1, iid=False)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'lasso':\n",
    "        \n",
    "    from sklearn.linear_model import Lasso\n",
    "    \n",
    "    param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "              'fit_intercept': [True, False],\n",
    "              'normalize' : [True, False],\n",
    "                 }\n",
    "    model_grid = RandomizedSearchCV(estimator=Lasso(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False,n_jobs=-1)\n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'ridge':\n",
    "    \n",
    "    from sklearn.linear_model import Ridge\n",
    "    \n",
    "    param_grid = {\"alpha\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "              \"fit_intercept\": [True, False],\n",
    "              \"normalize\": [True, False],\n",
    "              }\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=Ridge(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'en':\n",
    "    \n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    \n",
    "    param_grid = {'alpha': [0.0001,0.001,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                  'l1_ratio' : [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'normalize': [True, False]\n",
    "                 } \n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=ElasticNet(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "  elif estimator == 'lars':\n",
    "    \n",
    "    from sklearn.linear_model import Lars\n",
    "    \n",
    "    param_grid = {'fit_intercept':[True, False],\n",
    "                 'normalize' : [True, False],\n",
    "                 'eps': [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.0005, 0.005, 0.00005, 0.02, 0.007]}\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=Lars(), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_  \n",
    "    \n",
    "  elif estimator == 'llars':\n",
    "\n",
    "    from sklearn.linear_model import LassoLars\n",
    "    \n",
    "    param_grid = {'alpha': [0.0001,0.001,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'fit_intercept':[True, False],\n",
    "                 'normalize' : [True, False],\n",
    "                 'eps': [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.0005, 0.005, 0.00005, 0.02, 0.007]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=LassoLars(), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1)\n",
    "        \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "    \n",
    "  elif estimator == 'omp':\n",
    "    \n",
    "    from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "    import random\n",
    "    \n",
    "    param_grid = {'n_nonzero_coefs': range(0,len(X_train.columns)+1),\n",
    "                  'fit_intercept' : [True, False],\n",
    "                  'normalize': [True, False]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=OrthogonalMatchingPursuit(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'br':\n",
    "   \n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "    param_grid = {'alpha_1': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'alpha_2': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'lambda_1': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'lambda_2': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'compute_score': [True, False],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'normalize': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=BayesianRidge(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "\n",
    "  elif estimator == 'ard':\n",
    "   \n",
    "    from sklearn.linear_model import ARDRegression\n",
    "\n",
    "    param_grid = {'alpha_1': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'alpha_2': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'lambda_1': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'lambda_2': [0.0000001, 0.000001, 0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "                  'threshold_lambda' : [5000,10000,15000,20000,25000,30000,35000,40000,45000,50000,55000,60000],\n",
    "                  'compute_score': [True, False],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'normalize': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=ARDRegression(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_       \n",
    "    \n",
    "  elif estimator == 'par':\n",
    "   \n",
    "    from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "    param_grid = {'C': [0.01, 0.005, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'early_stopping' : [True, False],\n",
    "                  #'validation_fraction': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                  'loss' : ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                  'epsilon' : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "                  'shuffle' : [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=PassiveAggressiveRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_         \n",
    "    \n",
    "  elif estimator == 'ransac':\n",
    "   \n",
    "    from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "    param_grid = {'min_samples': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                  'max_trials': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'max_skips': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'stop_n_inliers': [1,2,3,4,5,6,7,8,9,10],\n",
    "                  'stop_probability': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                  'loss' : ['absolute_loss', 'squared_loss'],\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RANSACRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_         \n",
    "    \n",
    "  elif estimator == 'tr':\n",
    "   \n",
    "    from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "    param_grid = {'fit_intercept': [True, False],\n",
    "                  'max_subpopulation': [5000, 10000, 15000, 20000, 25000, 30000, 40000, 50000]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=TheilSenRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "    \n",
    "  elif estimator == 'huber':\n",
    "   \n",
    "    from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "    param_grid = {'epsilon': [1.1, 1.2, 1.3, 1.35, 1.4, 1.5, 1.55, 1.6, 1.7, 1.8, 1.9],\n",
    "                  'alpha': [0.00001, 0.0001, 0.0003, 0.005, 0.05, 0.1, 0.0005, 0.15],\n",
    "                  'fit_intercept' : [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=HuberRegressor(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'kr':\n",
    "    \n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "    param_grid = {'alpha': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1] }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=KernelRidge(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_       \n",
    "    \n",
    "  elif estimator == 'svm':\n",
    "    \n",
    "    from sklearn.svm import SVR\n",
    "\n",
    "    param_grid = {#'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                  #'float' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'C' : [0.01, 0.005, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                  'epsilon' : [1.1, 1.2, 1.3, 1.35, 1.4, 1.5, 1.55, 1.6, 1.7, 1.8, 1.9],\n",
    "                  'shrinking': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SVR(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "    \n",
    "  elif estimator == 'knn':\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "    param_grid = {'n_neighbors': range(1,51),\n",
    "                 'weights' :  ['uniform', 'distance'],\n",
    "                 'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "                 'leaf_size': [10,20,30,40,50,60,70,80,90]\n",
    "                 } \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=KNeighborsRegressor(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_         \n",
    "    \n",
    "  elif estimator == 'dt':\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    param_grid = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "                  \"max_features\": np.random.randint(3, len(X_train.columns),4),\n",
    "                  \"min_samples_leaf\": [0.1,0.2,0.3,0.4,0.5],\n",
    "                  \"min_samples_split\" : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                  \"min_weight_fraction_leaf\" : [0.1,0.2,0.3,0.4,0.5],\n",
    "                  \"min_impurity_decrease\" : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                  \"criterion\": [\"mse\", \"mae\", \"friedman_mse\"],\n",
    "                  #\"max_leaf_nodes\" : [1,2,3,4,5,6,7,8,9,10,None]\n",
    "                 } \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_         \n",
    "        \n",
    "  elif estimator == 'rf':\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    \n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['mse', 'mae'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                  }\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_       \n",
    "    \n",
    "\n",
    "  elif estimator == 'et':\n",
    "    \n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    \n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['mse', 'mae'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                  }  \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=ExtraTreesRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_       \n",
    "                \n",
    "  elif estimator == 'ada':\n",
    "    \n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    \n",
    "    param_grid = {'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'loss' : [\"linear\", \"square\", \"exponential\"]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=AdaBoostRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_ \n",
    "\n",
    "  elif estimator == 'gbr':\n",
    "    \n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "    param_grid = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "                  'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'subsample' : [0.1,0.3,0.5,0.7,0.9,1],\n",
    "                  'criterion' : ['friedman_mse', 'mse', 'mae'],\n",
    "                  'min_samples_split' : [2,4,5,7,9,10],\n",
    "                  'min_samples_leaf' : [1,2,3,4,5],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2']\n",
    "                 }     \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GradientBoostingRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_         \n",
    "\n",
    "  elif estimator == 'mlp':\n",
    "    \n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    \n",
    "    param_grid = {'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "                  'solver' : ['lbfgs', 'adam'],\n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.00001, 0.003, 0.0003, 0.0005, 0.005, 0.05],\n",
    "                  'hidden_layer_sizes': np.random.randint(50,150,10),\n",
    "                  'activation': [\"tanh\", \"identity\", \"logistic\",\"relu\"]\n",
    "                  }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=MLPRegressor(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)    \n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "    \n",
    "  if estimator == 'dt' and ensemble == True and method == 'Bagging':\n",
    "    \n",
    "    #when using normal BaggingRegressor() DT estimator raise's an exception for max_features parameter. Hence a separate \n",
    "    #call has been made for estimator='dt' and method = 'Bagging' where max_features has been removed from param_grid_dt.\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import BaggingRegressor\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "    \n",
    "    param_grid_dt = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "                     \"min_samples_leaf\": [2,3,4],\n",
    "                     \"min_samples_leaf\": [0.1,0.2,0.3,0.4,0.5],\n",
    "                     \"min_samples_split\" : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                     \"min_weight_fraction_leaf\" : [0.1,0.2,0.3,0.4,0.5],\n",
    "                     \"min_impurity_decrease\" : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                     \"criterion\": [\"mse\", \"mae\", \"friedman_mse\"]}\n",
    "\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeRegressor(random_state=seed), param_distributions=param_grid_dt,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "    best_model = BaggingRegressor(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "  elif ensemble and method == 'Bagging':\n",
    "    \n",
    "    from sklearn.ensemble import BaggingRegressor\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "\n",
    "    best_model = BaggingRegressor(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "      \n",
    "  elif ensemble and method =='Boosting':\n",
    "    \n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    \n",
    "    param_grid = {'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'loss' : [\"linear\", \"square\", \"exponential\"]\n",
    "                 }          \n",
    "    \n",
    "    best_model = AdaBoostRegressor(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    "\n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    pred_ = model.predict(Xtest)\n",
    "    mae = mean_absolute_error(ytest,pred_)\n",
    "    mse = mean_squared_error(ytest,pred_)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(ytest,pred_)\n",
    "    max_error_ = max_error(ytest,pred_)\n",
    "    score_mae = np.append(score_mae,mae)\n",
    "    score_mse = np.append(score_mse,mse)\n",
    "    score_rmse = np.append(score_rmse,rmse)\n",
    "    score_r2 =np.append(score_r2,r2)\n",
    "    score_max_error = np.append(score_max_error,max_error_)\n",
    " \n",
    "  mean_mae=np.mean(score_mae)\n",
    "  mean_mse=np.mean(score_mse)\n",
    "  mean_rmse=np.mean(score_rmse)\n",
    "  mean_r2=np.mean(score_r2)\n",
    "  mean_max_error=np.mean(score_max_error)\n",
    "  std_mae=np.std(score_mae)\n",
    "  std_mse=np.std(score_mse)\n",
    "  std_rmse=np.std(score_rmse)\n",
    "  std_r2=np.std(score_r2)\n",
    "  std_max_error=np.std(score_max_error)\n",
    "    \n",
    "  avgs_mae = np.append(avgs_mae, mean_mae)\n",
    "  avgs_mae = np.append(avgs_mae, std_mae) \n",
    "  avgs_mse = np.append(avgs_mse, mean_mse)\n",
    "  avgs_mse = np.append(avgs_mse, std_mse)\n",
    "  avgs_rmse = np.append(avgs_rmse, mean_rmse)\n",
    "  avgs_rmse = np.append(avgs_rmse, std_rmse)\n",
    "  avgs_r2 = np.append(avgs_r2, mean_r2)\n",
    "  avgs_r2 = np.append(avgs_r2, std_r2)\n",
    "  avgs_max_error = np.append(avgs_max_error, mean_max_error)\n",
    "  avgs_max_error = np.append(avgs_max_error, std_max_error)\n",
    "    \n",
    "  model_results = pd.DataFrame({'MAE': score_mae, 'MSE': score_mse, 'RMSE' : score_rmse, \n",
    "                                'R2' : score_r2, 'ME' : score_max_error})\n",
    "\n",
    "  model_avgs = pd.DataFrame({'MAE': avgs_mae, 'MSE': avgs_mse, 'RMSE' : avgs_rmse, 'R2' : avgs_r2,\n",
    "                             'ME' : avgs_max_error},index=['Mean', 'SD'])\n",
    "    \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)  \n",
    "  model_results = model_results.style.set_table_styles([ dict(selector='th', props=[('text-align', 'center')] ) ])\n",
    " \n",
    "  if verbose:\n",
    "    display(model_results)\n",
    "    return best_model\n",
    "  else:\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(estimator, \n",
    "               plot = 'residual'):\n",
    "    \n",
    "    model = estimator\n",
    "    \n",
    "    if plot == 'residual':\n",
    "        from yellowbrick.regressor import ResidualsPlot\n",
    "        visualizer = ResidualsPlot(model)\n",
    "        #visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        visualizer.show()\n",
    "        \n",
    "    elif plot == 'error':\n",
    "        from yellowbrick.regressor import PredictionError\n",
    "        visualizer = PredictionError(model)\n",
    "        #visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.show()\n",
    "    \n",
    "    elif plot == 'cooks':\n",
    "        from yellowbrick.regressor import CooksDistance\n",
    "        visualizer = CooksDistance()\n",
    "        visualizer.fit(X, y)\n",
    "        visualizer.show()\n",
    "\n",
    "    elif plot == 'feature':\n",
    "        variables = abs(model.coef_)\n",
    "        col_names = np.array(X_train.columns)\n",
    "        global coef_df\n",
    "        coef_df = pd.DataFrame({'Variable': X_train.columns, 'Value': variables})\n",
    "        sorted_df = coef_df.sort_values(by='Value')\n",
    "        my_range=range(1,len(sorted_df.index)+1)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.hlines(y=my_range, xmin=0, xmax=sorted_df['Value'], color='skyblue')\n",
    "        plt.plot(sorted_df['Value'], my_range, \"o\")\n",
    "        plt.yticks(my_range, sorted_df['Variable'])\n",
    "        plt.title(\"Feature Importance Plot\")\n",
    "        plt.xlabel('Variable Importance')\n",
    "        plt.ylabel('Features') \n",
    "        var_imp = sorted_df.reset_index(drop=True)\n",
    "        var_imp_array = np.array(var_imp['Variable'])\n",
    "        var_imp_array_top_n = var_imp_array[0:len(var_imp_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacknet(estimator_list,\n",
    "                    meta_model = None,\n",
    "                    fold = 10,\n",
    "                    round = 4,\n",
    "                    restack = False):\n",
    "    \n",
    "    #global base_array_df\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_squared_log_error\n",
    "    from sklearn.metrics import max_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    base_level = estimator_list[0]\n",
    "    inter_level = estimator_list[1:]\n",
    "    data_X = X_train\n",
    "    data_y = y_train\n",
    "    \n",
    "    #defining meta model\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    if meta_model == None:\n",
    "        meta_model = LinearRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_array_df = pd.DataFrame()\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in base_level:\n",
    "                     \n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold)#, method=predict_method)\n",
    "        base_array = base_array\n",
    "        base_array = pd.DataFrame(base_array)\n",
    "        base_array_df = pd.concat([base_array_df, base_array], axis=1)\n",
    "        base_array = np.empty((0,0))  \n",
    "        \n",
    "    for level in inter_level:\n",
    "        \n",
    "        for model in level:\n",
    "            \n",
    "            base_array = cross_val_predict(model,base_array_df,base_prediction,cv=fold)#, method=predict_method)\n",
    "            base_array = base_array\n",
    "            base_array = pd.DataFrame(base_array)\n",
    "            base_array_df = pd.concat([base_array, base_array_df], axis=1)\n",
    "            base_array = np.empty((0,0))\n",
    "        \n",
    "        if restack == False:\n",
    "            base_array_df = base_array_df.iloc[:,:len(level)]\n",
    "        else:\n",
    "            base_array_df = base_array_df\n",
    "    \n",
    "    model = meta_model\n",
    "    \n",
    "    kf = KFold(fold, random_state=seed) #capturing fold requested by user\n",
    "\n",
    "    score_mae =np.empty((0,0))\n",
    "    score_mse =np.empty((0,0))\n",
    "    score_rmse =np.empty((0,0))\n",
    "    score_r2 =np.empty((0,0))\n",
    "    score_max_error =np.empty((0,0))\n",
    "    avgs_mae =np.empty((0,0))\n",
    "    avgs_mse =np.empty((0,0))\n",
    "    avgs_rmse =np.empty((0,0))\n",
    "    avgs_r2 =np.empty((0,0))\n",
    "    avgs_max_error =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_ = model.predict(Xtest)\n",
    "        mae = mean_absolute_error(ytest,pred_)\n",
    "        mse = mean_squared_error(ytest,pred_)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(ytest,pred_)\n",
    "        max_error_ = max_error(ytest,pred_)\n",
    "        score_mae = np.append(score_mae,mae)\n",
    "        score_mse = np.append(score_mse,mse)\n",
    "        score_rmse = np.append(score_rmse,rmse)\n",
    "        score_r2 =np.append(score_r2,r2)\n",
    "        score_max_error = np.append(score_max_error,max_error_)\n",
    "\n",
    "    mean_mae=np.mean(score_mae)\n",
    "    mean_mse=np.mean(score_mse)\n",
    "    mean_rmse=np.mean(score_rmse)\n",
    "    mean_r2=np.mean(score_r2)\n",
    "    mean_max_error=np.mean(score_max_error)\n",
    "    std_mae=np.std(score_mae)\n",
    "    std_mse=np.std(score_mse)\n",
    "    std_rmse=np.std(score_rmse)\n",
    "    std_r2=np.std(score_r2)\n",
    "    std_max_error=np.std(score_max_error)\n",
    "\n",
    "    avgs_mae = np.append(avgs_mae, mean_mae)\n",
    "    avgs_mae = np.append(avgs_mae, std_mae) \n",
    "    avgs_mse = np.append(avgs_mse, mean_mse)\n",
    "    avgs_mse = np.append(avgs_mse, std_mse)\n",
    "    avgs_rmse = np.append(avgs_rmse, mean_rmse)\n",
    "    avgs_rmse = np.append(avgs_rmse, std_rmse)\n",
    "    avgs_r2 = np.append(avgs_r2, mean_r2)\n",
    "    avgs_r2 = np.append(avgs_r2, std_r2)\n",
    "    avgs_max_error = np.append(avgs_max_error, mean_max_error)\n",
    "    avgs_max_error = np.append(avgs_max_error, std_max_error)\n",
    "\n",
    "    model_results = pd.DataFrame({'MAE': score_mae, 'MSE': score_mse, 'RMSE' : score_rmse, \n",
    "                                'R2' : score_r2, 'ME' : score_max_error})\n",
    "\n",
    "    model_avgs = pd.DataFrame({'MAE': avgs_mae, 'MSE': avgs_mse, 'RMSE' : avgs_rmse, 'R2' : avgs_r2,\n",
    "                             'ME' : avgs_max_error},index=['Mean', 'SD'])\n",
    "\n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    model_results = model_results.style.set_table_styles([ dict(selector='th', props=[('text-align', 'center')] ) ])    \n",
    "    display(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    from sklearn.externals import joblib\n",
    "    model_name = model_name + '.pkl'\n",
    "    joblib.dump(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    from sklearn.externals import joblib\n",
    "    model_name = model_name + '.pkl'\n",
    "    return joblib.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Codes until Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work in Progress / Future Release "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(data_X=X_train, n=3):\n",
    "    global X_train\n",
    "    drop_list = var_imp_array_top_n[0:n]\n",
    "    X_train.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules now Available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. plot_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. tune_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0. ensemble_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 blend_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0. stack_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0. create_stacknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0. save_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0. load_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0. optimize_model (Future Release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.0. predict_stacknet (Future Release)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
