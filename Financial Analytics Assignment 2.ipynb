{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pd_pi\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.pipeline import Pipeline as pipe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finance Assignment 2 Data\n",
    "data = pd.read_csv('finance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(data, \n",
    "          target, \n",
    "          split=0.05):\n",
    "    \n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X = data.drop(target,axis=1)\n",
    "  y = data[target]\n",
    "  global X_train, X_test, y_train, y_test, seed\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split)\n",
    "  import random\n",
    "  seed = random.randint(150,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup(data, 'BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(estimator = None, \n",
    "                 ensemble = False, \n",
    "                 method = 'Bagging', \n",
    "                 fold = 10, \n",
    "                 round = 4,  \n",
    "                 verbose = True):\n",
    "  \n",
    "  #defining X_train and y_train    \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "  \n",
    "  #ignore co-linearity warnings for qda and lda \n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "  \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.svm import LinearSVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold  \n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from yellowbrick.classifier import roc_auc\n",
    "  from yellowbrick.classifier import ROCAUC\n",
    "  from yellowbrick.classifier import discrimination_threshold\n",
    "  from yellowbrick.classifier import precision_recall_curve\n",
    "  from yellowbrick.classifier import confusion_matrix\n",
    "  from yellowbrick.classifier import class_prediction_error\n",
    "  from yellowbrick.classifier import classification_report\n",
    "    \n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "  if estimator == None:\n",
    "    print(\"Please enter your custom model as on object or choose from model library. If you have previously defined the estimator, the output is generated using the same estimator\") \n",
    "  elif estimator == 'lr':\n",
    "    model = LogisticRegression(random_state=seed)\n",
    "    full_name = 'Logistic Regression'\n",
    "  elif estimator == 'knn':\n",
    "    model = KNeighborsClassifier()\n",
    "    full_name = 'K Nearest Neighbours'\n",
    "  elif estimator == 'nb':\n",
    "    model = GaussianNB()\n",
    "    full_name = 'Naive Bayes'\n",
    "  elif estimator == 'dt':\n",
    "    model = DecisionTreeClassifier(random_state=seed)\n",
    "    full_name = 'Decision Tree'\n",
    "  elif estimator == 'svm':\n",
    "    model = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "    full_name = 'Support Vector Machine'\n",
    "  elif estimator == 'rbfsvm':\n",
    "    model = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "    full_name = 'RBF SVM'\n",
    "  elif estimator == 'gpc':\n",
    "    model = GaussianProcessClassifier(random_state=seed)\n",
    "    full_name = 'Gaussian Process Classifier'\n",
    "  elif estimator == 'mlp':\n",
    "    model = MLPClassifier(max_iter=500, random_state=seed)\n",
    "    full_name = 'Multi Level Perceptron'    \n",
    "  elif estimator == 'ridge':\n",
    "    model = RidgeClassifier(random_state=seed)\n",
    "    full_name = 'Ridge Classifier'        \n",
    "  elif estimator == 'rf':\n",
    "    model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "    full_name = 'Random Forest Classifier'    \n",
    "  elif estimator == 'qda':\n",
    "    model = QuadraticDiscriminantAnalysis()\n",
    "    full_name = 'Quadratic Discriminant Analysis'    \n",
    "  elif estimator == 'ada':\n",
    "    model = AdaBoostClassifier(random_state=seed)\n",
    "    full_name = 'AdaBoost Classifier'        \n",
    "  elif estimator == 'gbc':\n",
    "    model = GradientBoostingClassifier(random_state=seed)\n",
    "    full_name = 'Gradient Boosting Classifier'          \n",
    "  elif estimator == 'lda':\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    full_name = 'Linear Discriminant Analysis'\n",
    "  elif estimator == 'et':\n",
    "    model = ExtraTreesClassifier(random_state=seed)\n",
    "    full_name = 'Extra Trees Classifier'\n",
    "  else:\n",
    "    model = estimator\n",
    "    full_name = str(model).split(\"(\")[0]\n",
    "  \n",
    "  #checking ensemble method\n",
    "    \n",
    "  if ensemble and method == 'Bagging':\n",
    "    model = BaggingClassifier(model,bootstrap=True,n_estimators=10, random_state=seed)\n",
    "  elif ensemble and method == 'Boosting':\n",
    "    model = AdaBoostClassifier(model, random_state=seed)\n",
    "  elif method == 'Boosting':\n",
    "    model = AdaBoostClassifier(model, random_state=seed)\n",
    "     \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.00\n",
    "        pred_prob = 0.00\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.00\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa) \n",
    "       \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "  model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  model_results_unpivot = pd.melt(model_results,value_vars=['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa'])\n",
    "  model_results_unpivot.columns = ['Metric', 'Measure']\n",
    "  model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)  \n",
    " \n",
    "  if verbose:\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(model_results.to_html()))\n",
    "    return model\n",
    "  else:\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_model(estimator,\n",
    "                   method = 'Bagging', \n",
    "                   fold = 10,\n",
    "                   n_estimators = 10,\n",
    "                   round = 4,  \n",
    "                   verbose = True):\n",
    "    \n",
    "    #defining X_train and y_train    \n",
    "    data_X = X_train\n",
    "    data_y = y_train\n",
    "  \n",
    "    #ignore co-linearity warnings for qda and lda \n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore') \n",
    "    \n",
    "    #defining estimator as model\n",
    "    model = estimator\n",
    "     \n",
    "    if method == 'Bagging':\n",
    "        from sklearn.ensemble import BaggingClassifier\n",
    "        model = BaggingClassifier(model,bootstrap=True,n_estimators=n_estimators, random_state=seed)\n",
    "        \n",
    "    else:\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        model = AdaBoostClassifier(model, random_state=seed)\n",
    "    \n",
    "    kf = StratifiedKFold(fold, random_state=seed)\n",
    "    \n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "            model.fit(Xtrain,ytrain)\n",
    "            pred_prob = model.predict_proba(Xtest)\n",
    "            pred_prob = pred_prob[:,1]\n",
    "            pred_ = model.predict(Xtest)\n",
    "            sca = metrics.accuracy_score(ytest,pred_)\n",
    "            sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "            recall = metrics.recall_score(ytest,pred_)\n",
    "            precision = metrics.precision_score(ytest,pred_)\n",
    "            kappa = cohen_kappa_score(ytest,pred_)\n",
    "            f1 = metrics.f1_score(ytest,pred_)\n",
    "            score_acc = np.append(score_acc,sca)\n",
    "            score_auc = np.append(score_auc,sc)\n",
    "            score_recall = np.append(score_recall,recall)\n",
    "            score_precision = np.append(score_precision,precision)\n",
    "            score_f1 =np.append(score_f1,f1)\n",
    "            score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            model.fit(Xtrain,ytrain)\n",
    "            pred_prob = 0.00\n",
    "            pred_prob = 0.00\n",
    "            pred_ = model.predict(Xtest)\n",
    "            sca = metrics.accuracy_score(ytest,pred_)\n",
    "            sc = 0.00\n",
    "            recall = metrics.recall_score(ytest,pred_)\n",
    "            precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "            kappa = cohen_kappa_score(ytest,pred_)\n",
    "            f1 = metrics.f1_score(ytest,pred_)\n",
    "            score_acc = np.append(score_acc,sca)\n",
    "            score_auc = np.append(score_auc,sc)\n",
    "            score_recall = np.append(score_recall,recall)\n",
    "            score_precision = np.append(score_precision,precision)\n",
    "            score_f1 =np.append(score_f1,f1)\n",
    "            score_kappa =np.append(score_kappa,kappa) \n",
    "       \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "\n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "\n",
    "    model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    model_results_unpivot = pd.melt(model_results,value_vars=['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa'])\n",
    "    model_results_unpivot.columns = ['Metric', 'Measure']\n",
    "    model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "\n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    \n",
    "    model = model\n",
    "    \n",
    "    if verbose:\n",
    "        display(model_results)\n",
    "        return model\n",
    "    else:\n",
    "        return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(estimator, \n",
    "               plot = 'auc', \n",
    "               manifold='tsne',\n",
    "               features=5):\n",
    "    \n",
    "    model = estimator\n",
    "    \n",
    "    if plot == 'auc':\n",
    "        from yellowbrick.classifier import ROCAUC\n",
    "        visualizer = ROCAUC(model)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    elif plot == 'threshold':\n",
    "        from yellowbrick.classifier import DiscriminationThreshold\n",
    "        visualizer = DiscriminationThreshold(model, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "    \n",
    "    elif plot == 'pr':\n",
    "        from yellowbrick.classifier import PrecisionRecallCurve\n",
    "        visualizer = PrecisionRecallCurve(model, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "\n",
    "    elif plot == 'confusion_matrix':\n",
    "        from yellowbrick.classifier import ConfusionMatrix\n",
    "        visualizer = ConfusionMatrix(model, random_state=seed, fontsize=15, cmap=\"Greens\")\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "    \n",
    "    elif plot == 'error':\n",
    "        from yellowbrick.classifier import ClassPredictionError\n",
    "        visualizer = ClassPredictionError(model, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "\n",
    "    elif plot == 'class_report':\n",
    "        from yellowbrick.classifier import ClassificationReport\n",
    "        visualizer = ClassificationReport(model, random_state=seed, support=True)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    elif plot == 'boundary':\n",
    "        \n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "        from yellowbrick.contrib.classifier import DecisionViz        \n",
    "\n",
    "        X_train_transformed = X_train.select_dtypes(include='float64')\n",
    "        X_test_transformed = X_test.select_dtypes(include='float64')\n",
    "        X_train_transformed = StandardScaler().fit_transform(X_train_transformed)\n",
    "        X_test_transformed = StandardScaler().fit_transform(X_test_transformed)\n",
    "        pca = PCA(n_components=2, random_state = seed)\n",
    "        X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "        X_test_transformed = pca.fit_transform(X_test_transformed)\n",
    "\n",
    "        y_train_transformed = np.array(y_train)\n",
    "        y_test_transformed = np.array(y_test)\n",
    "        \n",
    "        model_transformed = model\n",
    "        \n",
    "        viz = DecisionViz(model_transformed)\n",
    "        viz.fit(X_train_transformed, y_train_transformed, features=['Feature One', 'Feature Two'], classes=['A', 'B'])\n",
    "        viz.draw(X_test_transformed, y_test_transformed)\n",
    "        viz.poof()\n",
    "        \n",
    "    elif plot == 'rfe':\n",
    "        from yellowbrick.model_selection import RFECV    \n",
    "        visualizer = RFECV(model, cv=10)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.poof()\n",
    "        \n",
    "        \n",
    "    elif plot == 'learning':\n",
    "        from yellowbrick.model_selection import LearningCurve\n",
    "        sizes = np.linspace(0.3, 1.0, 10)  \n",
    "        visualizer = LearningCurve(model, cv=10, scoring='f1_weighted', train_sizes=sizes, n_jobs=1, random_state=seed)\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    \n",
    "    elif plot == 'manifold':\n",
    "        from yellowbrick.features import Manifold\n",
    "        X_train_transformed = X_train.select_dtypes(include='float64') \n",
    "        visualizer = Manifold(manifold=manifold, random_state = seed)\n",
    "        visualizer.fit_transform(X_train_transformed, y_train)\n",
    "        visualizer.poof()       \n",
    "        \n",
    "    elif plot == 'calibration':      \n",
    "                \n",
    "        from sklearn.calibration import calibration_curve\n",
    "        \n",
    "        model_name = str(model).split(\"(\")[0]\n",
    "        \n",
    "        plt.figure(figsize=(7, 6))\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "        #model.fit(X_train, y_train)\n",
    "        prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "        prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "        fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "        ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s\" % (model_name, ))\n",
    "\n",
    "        ax1.set_ylabel(\"Fraction of positives\")\n",
    "        ax1.set_ylim([0, 1])\n",
    "        ax1.set_xlim([0, 1])\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_title('Calibration plots  (reliability curve)')\n",
    "        ax1.set_facecolor('white')\n",
    "        ax1.grid(b=True, color='grey', linewidth=0.5, linestyle = '-')\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "        \n",
    "    elif plot == 'vc':\n",
    "    \n",
    "        if hasattr(model, 'max_depth'):\n",
    "            param_name='max_depth'\n",
    "        else:\n",
    "            param_name='xxx'\n",
    "       \n",
    "        from yellowbrick.model_selection import ValidationCurve\n",
    "        viz = ValidationCurve(model, param_name=param_name, param_range=np.arange(1,11), scoring='f1_weighted',cv=10, \n",
    "                              random_state=seed)\n",
    "        viz.fit(X_train, y_train)\n",
    "        viz.poof()\n",
    "        \n",
    "    elif plot == 'dimension':\n",
    "    \n",
    "        from yellowbrick.features import RadViz\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        X_train_transformed = X_train.select_dtypes(include='float64') \n",
    "        X_train_transformed = StandardScaler().fit_transform(X_train_transformed)\n",
    "        y_train_transformed = np.array(y_train)\n",
    "\n",
    "        pca = PCA(n_components=features, random_state=seed)\n",
    "        X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "\n",
    "        classes = [\"1\", \"0\"]\n",
    "        visualizer = RadViz(classes=classes, alpha=0.25)\n",
    "        visualizer.fit(X_train_transformed, y_train_transformed)     \n",
    "        visualizer.transform(X_train_transformed)\n",
    "        visualizer.poof()\n",
    "        \n",
    "    elif plot == 'feature':\n",
    "        variables = abs(model.coef_[0])\n",
    "        col_names = np.array(X_train.columns)\n",
    "        coef_df = pd.DataFrame({'Variable': X_train.columns, 'Value': variables})\n",
    "        sorted_df = coef_df.sort_values(by='Value')\n",
    "        my_range=range(1,len(sorted_df.index)+1)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.hlines(y=my_range, xmin=0, xmax=sorted_df['Value'], color='skyblue')\n",
    "        plt.plot(sorted_df['Value'], my_range, \"o\")\n",
    "        plt.yticks(my_range, sorted_df['Variable'])\n",
    "        plt.title(\"Feature Importance Plot\")\n",
    "        plt.xlabel('Variable Importance')\n",
    "        plt.ylabel('Features') \n",
    "        var_imp = sorted_df.reset_index(drop=True)\n",
    "        var_imp_array = np.array(var_imp['Variable'])\n",
    "        var_imp_array_top_n = var_imp_array[0:len(var_imp_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_library = None, \n",
    "                   fold = 10, \n",
    "                   round = 4, \n",
    "                   sort = 'Accuracy', \n",
    "                   blacklist = None):\n",
    "  \n",
    "  #ignore warnings\n",
    "  import warnings\n",
    "  warnings.filterwarnings('ignore') \n",
    "    \n",
    "  #defining X_train and y_train\n",
    "  data_X = X_train\n",
    "  data_y=y_train\n",
    "\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  import random\n",
    "  import pandas.io.formats.style\n",
    "\n",
    "  lr = LogisticRegression(random_state=seed)\n",
    "  knn = KNeighborsClassifier()\n",
    "  nb = GaussianNB()\n",
    "  dt = DecisionTreeClassifier(random_state=seed)\n",
    "  svm = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "  rbfsvm = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "  gpc = GaussianProcessClassifier(random_state=seed)\n",
    "  mlp = MLPClassifier(max_iter=500, random_state=seed)\n",
    "  ridge = RidgeClassifier(random_state=seed)\n",
    "  rf = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "  qda = QuadraticDiscriminantAnalysis()\n",
    "  ada = AdaBoostClassifier(random_state=seed)\n",
    "  gbc = GradientBoostingClassifier(random_state=seed)\n",
    "  lda = LinearDiscriminantAnalysis()\n",
    "  et = ExtraTreesClassifier(random_state=seed)\n",
    "  \n",
    "  #blacklist models\n",
    "\n",
    "  if model_library != None:\n",
    "    \n",
    "    model_library = model_library\n",
    "    \n",
    "    model_names = []\n",
    "    \n",
    "    for names in model_library:\n",
    "        \n",
    "        model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "        \n",
    "        import re \n",
    "        \n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "            \n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final    \n",
    "    \n",
    "  else:\n",
    "        \n",
    "    if blacklist == None:\n",
    "        \n",
    "        model_library = [lr, knn, nb, dt, svm, rbfsvm, gpc, mlp, ridge, rf, qda, ada, gbc, lda, et]\n",
    "    \n",
    "        model_names = []\n",
    "    \n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "    \n",
    "        import re \n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model_library_values = ['lr', 'knn', 'nb', 'dt', 'svm', 'rbfsvm', 'gpc', 'mlp', 'ridge', 'rf', 'qda', \n",
    "                        'ada', 'gbc', 'lda', 'et']\n",
    "\n",
    "        location = []\n",
    "\n",
    "        for item in blacklist:\n",
    "            location.append(model_library_values.index(item))\n",
    "\n",
    "        model_library = [lr, knn, nb, dt, svm, rbfsvm, gpc, mlp, ridge, rf, qda, ada, gbc, lda, et]\n",
    "\n",
    "        for i in location:\n",
    "            del model_library[i]\n",
    "\n",
    "        model_names = []\n",
    "\n",
    "        for names in model_library:\n",
    "            model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "        import re\n",
    "\n",
    "        def putSpace(input):\n",
    "            words = re.findall('[A-Z][a-z]*', input)\n",
    "            words = ' '.join(words)\n",
    "            return words  \n",
    "\n",
    "        model_names_modified = []\n",
    "        for i in model_names:\n",
    "            model_names_modified.append(putSpace(i))\n",
    "\n",
    "        model_names = model_names_modified\n",
    "\n",
    "        model_names_final = []\n",
    "        for j in model_names:\n",
    "            if j == 'Gaussian N B':\n",
    "                model_names_final.append('Naive Bayes')\n",
    "            elif j == 'M L P Classifier':\n",
    "                model_names_final.append('MLP Classifier')\n",
    "            elif j == 'S G D Classifier':\n",
    "                model_names_final.append('SVM - Linear Kernel')\n",
    "            elif j == 'S V C':\n",
    "                model_names_final.append('SVM - Radial Kernel')\n",
    "            else: \n",
    "                model_names_final.append(j)\n",
    "\n",
    "        model_names = model_names_final\n",
    "\n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  score_acc_running = np.empty((0,0)) ##running total\n",
    "  avg_acc = np.empty((0,0))\n",
    "  avg_auc = np.empty((0,0))\n",
    "  avg_recall = np.empty((0,0))\n",
    "  avg_precision = np.empty((0,0))\n",
    "  avg_f1 = np.empty((0,0))\n",
    "  avg_kappa = np.empty((0,0))\n",
    "      \n",
    "  for model in model_library:\n",
    " \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "     \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "        \n",
    "          model.fit(Xtrain,ytrain)\n",
    "          pred_prob = model.predict_proba(Xtest)\n",
    "          pred_prob = pred_prob[:,1]\n",
    "          pred_ = model.predict(Xtest)\n",
    "          sca = metrics.accuracy_score(ytest,pred_)\n",
    "          sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "          recall = metrics.recall_score(ytest,pred_)\n",
    "          precision = metrics.precision_score(ytest,pred_)\n",
    "          kappa = cohen_kappa_score(ytest,pred_)\n",
    "          f1 = metrics.f1_score(ytest,pred_)\n",
    "          score_acc = np.append(score_acc,sca)\n",
    "          score_auc = np.append(score_auc,sc)\n",
    "          score_recall = np.append(score_recall,recall)\n",
    "          score_precision = np.append(score_precision,precision)\n",
    "          score_f1 =np.append(score_f1,f1)\n",
    "          score_kappa =np.append(score_kappa,kappa)              \n",
    "        \n",
    "        else:        \n",
    "        \n",
    "          model.fit(Xtrain,ytrain)\n",
    "          pred_prob = 0.00\n",
    "          pred_prob = 0.00\n",
    "          pred_ = model.predict(Xtest)\n",
    "          sca = metrics.accuracy_score(ytest,pred_)\n",
    "          sc = 0.00\n",
    "          recall = metrics.recall_score(ytest,pred_)\n",
    "          precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "          kappa = cohen_kappa_score(ytest,pred_)\n",
    "          f1 = metrics.f1_score(ytest,pred_)\n",
    "          score_acc = np.append(score_acc,sca)\n",
    "          score_auc = np.append(score_auc,sc)\n",
    "          score_recall = np.append(score_recall,recall)\n",
    "          score_precision = np.append(score_precision,precision)\n",
    "          score_f1 =np.append(score_f1,f1)\n",
    "          score_kappa =np.append(score_kappa,kappa) \n",
    "        \n",
    "    avg_acc = np.append(avg_acc,np.mean(score_acc))\n",
    "    avg_auc = np.append(avg_auc,np.mean(score_auc))\n",
    "    avg_recall = np.append(avg_recall,np.mean(score_recall))\n",
    "    avg_precision = np.append(avg_precision,np.mean(score_precision))\n",
    "    avg_f1 = np.append(avg_f1,np.mean(score_f1))\n",
    "    avg_kappa = np.append(avg_kappa,np.mean(score_kappa))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "  \n",
    "  def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "  compare_models_ = pd.DataFrame({'Model':model_names, 'Accuracy':avg_acc, 'AUC':avg_auc, \n",
    "                     'Recall':avg_recall, 'Prec.':avg_precision, \n",
    "                     'F1':avg_f1, 'Kappa': avg_kappa}).round(round).sort_values(by=[sort], \n",
    "                      ascending=False).reset_index(drop=True).style.apply(highlight_max,subset=['Accuracy','AUC','Recall',\n",
    "                      'Prec.','F1','Kappa'])\n",
    "  compare_models_ = compare_models_.set_properties(**{'text-align': 'left'})\n",
    "  compare_models_ = compare_models_.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
    "                  \n",
    "  return compare_models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(estimator = None, \n",
    "               fold = 10, \n",
    "               round = 4, \n",
    "               n_iter = 10, \n",
    "               optimize = 'accuracy',\n",
    "               ensemble = False, \n",
    "               method = 'Bagging',\n",
    "               verbose = True):\n",
    "   \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold  \n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "    \n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "  if estimator == 'knn':\n",
    "    \n",
    "    param_grid = {'n_neighbors': range(1,51),\n",
    "             'weights' : ['uniform', 'distance'],\n",
    "             'metric':[\"euclidean\", \"manhattan\"]\n",
    "                 }        \n",
    "    model_grid = RandomizedSearchCV(estimator=KNeighborsClassifier(), param_distributions=param_grid, \n",
    "                                    scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1, iid=False)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'lr':\n",
    "\n",
    "    param_grid = {'C': [1,5,10,25,50,100],\n",
    "              \"penalty\": [ 'l1', 'l2'],\n",
    "              \"class_weight\": [\"balanced\", None]\n",
    "                 }\n",
    "    model_grid = RandomizedSearchCV(estimator=LogisticRegression(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False,n_jobs=-1)\n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'dt':\n",
    "        \n",
    "    param_grid = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "              \"max_features\": np.random.randint(3, len(X_train.columns),4),\n",
    "              \"min_samples_leaf\": [2,3,4],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    " \n",
    "  elif estimator == 'mlp':\n",
    "    \n",
    "    param_grid = {'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "             'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'hidden_layer_sizes': np.random.randint(5,15,5),\n",
    "             'activation': [\"tanh\", \"identity\", \"logistic\",\"relu\"]\n",
    "             }\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=MLPClassifier(max_iter=1000, random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, cv=fold, \n",
    "                                    random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "  elif estimator == 'gpc':\n",
    "    \n",
    "    param_grid = {\"max_iter_predict\":[100,200,300,400,500,600,700,800,900,1000]}\n",
    "   \n",
    "    model_grid = RandomizedSearchCV(estimator=GaussianProcessClassifier(random_state=seed), param_distributions=param_grid,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "    \n",
    "  elif estimator == 'rbfsvm':\n",
    "\n",
    "    param_grid = {'C': [.5,1,10,50,100],\n",
    "            \"class_weight\": [\"balanced\", None]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "\n",
    "    \n",
    "  elif estimator == 'nb':\n",
    "\n",
    "    param_grid = {'var_smoothing': [0.000000001, 0.0000001, 0.00001, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007,\n",
    "                                    0.008, 0.009, 0.01, 0.1, 1]}\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GaussianNB(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'svm':\n",
    "   \n",
    "    param_grid = {'penalty': ['l2', 'l1','elasticnet'],\n",
    "                  'l1_ratio': [0,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.0002, 0.002, 0.02, 0.0005, 0.005, 0.05],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                  'eta0': [0.001, 0.01,0.05,0.1,0.2,0.3,0.4,0.5]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=SGDClassifier(loss='hinge', random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "\n",
    "  elif estimator == 'ridge':\n",
    "\n",
    "    param_grid = {'alpha': [0.0001,0.001,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'fit_intercept': [True, False],\n",
    "                  'normalize': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RidgeClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "   \n",
    "  elif estimator == 'rf':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_     \n",
    "   \n",
    "  elif estimator == 'ada':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'algorithm' : [\"SAMME\", \"SAMME.R\"]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=AdaBoostClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "\n",
    "  elif estimator == 'gbc':\n",
    "\n",
    "    param_grid = {'loss': ['deviance', 'exponential'],\n",
    "                  'n_estimators': [10, 40, 70, 80, 90, 100, 120, 140, 150],\n",
    "                  'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                  'subsample' : [0.1,0.3,0.5,0.7,0.9,1],\n",
    "                  'min_samples_split' : [2,4,5,7,9,10],\n",
    "                  'min_samples_leaf' : [1,2,3,4,5],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2']\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=GradientBoostingClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_   \n",
    "\n",
    "  elif estimator == 'qda':\n",
    "\n",
    "    param_grid = {'reg_param': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=QuadraticDiscriminantAnalysis(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_      \n",
    "\n",
    "  elif estimator == 'lda':\n",
    "\n",
    "    param_grid = {'solver' : ['lsqr', 'eigen'],\n",
    "                  'shrinkage': [0.0001, 0.001, 0.01, 0.0005, 0.005, 0.05, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=LinearDiscriminantAnalysis(), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_        \n",
    "\n",
    "  elif estimator == 'et':\n",
    "\n",
    "    param_grid = {'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                  'min_samples_split': [2, 5, 7, 9, 10],\n",
    "                  'min_samples_leaf' : [1, 2, 4],\n",
    "                  'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'bootstrap': [True, False]\n",
    "                 }    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=ExtraTreesClassifier(random_state=seed), \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_          \n",
    "    \n",
    "  if estimator == 'dt' and ensemble == True and method == 'Bagging':\n",
    "    \n",
    "    #when using normal BaggingClassifier() DT estimator raise's an exception for max_features parameter. Hence a separate \n",
    "    #call has been made for estimator='dt' and method = 'Bagging' where max_features has been removed from param_grid_dt.\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "    \n",
    "    param_grid_dt = {\"max_depth\": np.random.randint(3, (len(X_train.columns)*.85),4),\n",
    "                  \"min_samples_leaf\": [2,3,4],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    \n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=DecisionTreeClassifier(random_state=seed), param_distributions=param_grid_dt,\n",
    "                                   scoring=optimize, n_iter=n_iter, cv=fold, random_state=seed,\n",
    "                                   iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_\n",
    "    \n",
    "    best_model = BaggingClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "  elif ensemble and method == 'Bagging':\n",
    "    \n",
    "    param_grid = {'n_estimators': [10,15,20,25,30],\n",
    "                 'max_samples': [0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'max_features':[0.3,0.5,0.6,0.7,0.8,0.9],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'bootstrap_features': [True, False],\n",
    "                 }\n",
    "\n",
    "    best_model = BaggingClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    " \n",
    "    model_grid.fit(X_train,y_train)\n",
    "    model = model_grid.best_estimator_\n",
    "    best_model = model_grid.best_estimator_\n",
    "    best_model_param = model_grid.best_params_    \n",
    "  \n",
    "      \n",
    "  elif ensemble and method =='Boosting':\n",
    "        \n",
    "    param_grid = {'n_estimators': [25,35,50,60,70,75],\n",
    "                 'learning_rate': [1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2],\n",
    "                 }        \n",
    "    \n",
    "    best_model = AdaBoostClassifier(best_model, random_state=seed)\n",
    "    \n",
    "    model_grid = RandomizedSearchCV(estimator=best_model, \n",
    "                                    param_distributions=param_grid, scoring=optimize, n_iter=n_iter, \n",
    "                                    cv=fold, random_state=seed, iid=False, n_jobs=-1)\n",
    "\n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "    \n",
    "    if hasattr(best_model, 'predict_proba'):  \n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.00\n",
    "        pred_prob = 0.00\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.00\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_) #change pred_prob to pred_\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa) \n",
    "        \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "       \n",
    "  model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)\n",
    "  \n",
    "  if verbose:\n",
    "    display(model_results)\n",
    "    return best_model\n",
    "  else:\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models(estimator_list = None, \n",
    "                 fold = 10, \n",
    "                 round = 4, \n",
    "                 sort = 'Accuracy',\n",
    "                 method = 'soft'):\n",
    "  \n",
    "  data_X = X_train\n",
    "  data_y = y_train\n",
    "    \n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn.svm import SVC\n",
    "  from sklearn.gaussian_process.kernels import RBF\n",
    "  from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "  from sklearn.neural_network import MLPClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import pandas_profiling as pd_p\n",
    "  import seaborn as sns\n",
    "  from sklearn import preprocessing as pre\n",
    "  from sklearn.pipeline import Pipeline as pipe\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import RidgeClassifier\n",
    "  from sklearn.linear_model import Lasso\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  from sklearn.linear_model import SGDClassifier\n",
    "  from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "  from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "  from sklearn import metrics\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  from sklearn.model_selection import GridSearchCV\n",
    "  from sklearn.model_selection import RandomizedSearchCV\n",
    "  from scipy import stats\n",
    "  import random\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  from sklearn.model_selection import cross_val_predict\n",
    "  from sklearn.model_selection import cross_validate\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "  from sklearn.ensemble import ExtraTreesClassifier\n",
    "  from sklearn.model_selection import StratifiedKFold\n",
    "  from sklearn.metrics import roc_auc_score\n",
    "  from sklearn.metrics import cohen_kappa_score\n",
    "  from sklearn.ensemble import BaggingClassifier\n",
    "  from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "  kf = StratifiedKFold(fold, random_state=seed)\n",
    "\n",
    "  score_auc =np.empty((0,0))\n",
    "  score_acc =np.empty((0,0))\n",
    "  score_recall =np.empty((0,0))\n",
    "  score_precision =np.empty((0,0))\n",
    "  score_f1 =np.empty((0,0))\n",
    "  score_kappa =np.empty((0,0))\n",
    "  avgs_auc =np.empty((0,0))\n",
    "  avgs_acc =np.empty((0,0))\n",
    "  avgs_recall =np.empty((0,0))\n",
    "  avgs_precision =np.empty((0,0))\n",
    "  avgs_f1 =np.empty((0,0))\n",
    "  avgs_kappa =np.empty((0,0))\n",
    "  avg_acc = np.empty((0,0))\n",
    "  avg_auc = np.empty((0,0))\n",
    "  avg_recall = np.empty((0,0))\n",
    "  avg_precision = np.empty((0,0))\n",
    "  avg_f1 = np.empty((0,0))\n",
    "  avg_kappa = np.empty((0,0))\n",
    "  \n",
    "    \n",
    "  lr = LogisticRegression(random_state=seed)\n",
    "  knn = KNeighborsClassifier()\n",
    "  nb = GaussianNB()\n",
    "  dt = DecisionTreeClassifier(random_state=seed)\n",
    "  svm = SGDClassifier(max_iter=1000, tol=0.001, random_state=seed)\n",
    "  rbfsvm = SVC(gamma='auto', C=1, probability=True, kernel='rbf', random_state=seed)\n",
    "  gpc = GaussianProcessClassifier(random_state=seed)\n",
    "  mlp = MLPClassifier(max_iter=500, random_state=seed)\n",
    "  ridge = RidgeClassifier(random_state=seed)\n",
    "  rf = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "  qda = QuadraticDiscriminantAnalysis()\n",
    "  ada = AdaBoostClassifier(random_state=seed)\n",
    "  gbc = GradientBoostingClassifier(random_state=seed)\n",
    "  lda = LinearDiscriminantAnalysis()\n",
    "  et = ExtraTreesClassifier(random_state=seed)  \n",
    "    \n",
    "    \n",
    "  if estimator_list == None:\n",
    "    estimator_list = [lr,knn,nb,dt,svm,rbfsvm,gpc,mlp,ridge,rf,qda,ada,gbc,lda,et]\n",
    "    voting = 'hard'\n",
    "\n",
    "  else:\n",
    "    estimator_list = estimator_list\n",
    "    voting = method  \n",
    "      \n",
    "  model_names = []\n",
    "\n",
    "  for names in estimator_list:\n",
    "    model_names = np.append(model_names, str(names).split(\"(\")[0])\n",
    "\n",
    "  import re\n",
    "\n",
    "  def putSpace(input):\n",
    "        words = re.findall('[A-Z][a-z]*', input)\n",
    "        words = ' '.join(words)\n",
    "        return words  \n",
    "\n",
    "  model_names_modified = []\n",
    "  \n",
    "  for i in model_names:\n",
    "    model_names_modified.append(putSpace(i))\n",
    "\n",
    "    model_names = model_names_modified\n",
    "\n",
    "  model_names_final = []\n",
    "  \n",
    "  for j in model_names:\n",
    "    if j == 'Gaussian N B':\n",
    "        model_names_final.append('Naive Bayes')\n",
    "    elif j == 'M L P Classifier':\n",
    "        model_names_final.append('MLP Classifier')\n",
    "    elif j == 'S G D Classifier':\n",
    "        model_names_final.append('SVM - Linear Kernel')\n",
    "    elif j == 'S V C':\n",
    "        model_names_final.append('SVM - Radial Kernel')\n",
    "    else: \n",
    "        model_names_final.append(j)\n",
    "\n",
    "  model_names = model_names_final\n",
    "  estimator_list = estimator_list\n",
    "  estimator_list = zip(model_names, estimator_list)\n",
    "  estimator_list = set(estimator_list)\n",
    "  estimator_list = list(estimator_list)\n",
    "    \n",
    "  model = VotingClassifier(estimators=estimator_list, voting=voting, n_jobs=-1)\n",
    "  \n",
    "  for train_i , test_i in kf.split(data_X,data_y):\n",
    "    \n",
    "    Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "    ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]    \n",
    "    \n",
    "    if voting == 'hard':\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = 0.0\n",
    "        pred_prob = 0.0\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = 0.0\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.precision_score(ytest,pred_)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "       \n",
    "  mean_acc=np.mean(score_acc)\n",
    "  mean_auc=np.mean(score_auc)\n",
    "  mean_recall=np.mean(score_recall)\n",
    "  mean_precision=np.mean(score_precision)\n",
    "  mean_f1=np.mean(score_f1)\n",
    "  mean_kappa=np.mean(score_kappa)\n",
    "  std_acc=np.std(score_acc)\n",
    "  std_auc=np.std(score_auc)\n",
    "  std_recall=np.std(score_recall)\n",
    "  std_precision=np.std(score_precision)\n",
    "  std_f1=np.std(score_f1)\n",
    "  std_kappa=np.std(score_kappa)\n",
    "    \n",
    "  avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "  avgs_acc = np.append(avgs_acc, std_acc) \n",
    "  avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "  avgs_auc = np.append(avgs_auc, std_auc)\n",
    "  avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "  avgs_recall = np.append(avgs_recall, std_recall)\n",
    "  avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "  avgs_precision = np.append(avgs_precision, std_precision)\n",
    "  avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "  avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "  avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "  avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "  model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "  model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "  model_results = model_results.append(model_avgs)\n",
    "  model_results = model_results.round(round)\n",
    "  display(model_results)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_models(estimator_list, \n",
    "                 meta_model = None, \n",
    "                 fold = 10,\n",
    "                 round = 4, \n",
    "                 method = 'soft', \n",
    "                 restack = False, \n",
    "                 plot = False):\n",
    "    \n",
    "    #Capturing the method of stacking required by user. method='soft' means 'predict_proba' else 'predict'\n",
    "    \n",
    "    if method == 'soft':\n",
    "        predict_method = 'predict_proba'\n",
    "    elif method == 'hard':\n",
    "        predict_method = 'predict'\n",
    "    \n",
    "    #Defining meta model. Logistic Regression hardcoded for now\n",
    "    \n",
    "    if meta_model == None:\n",
    "        meta_model = LogisticRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    #defining model_library model names\n",
    "    \n",
    "    model_names = np.zeros(0)\n",
    "    for item in estimator_list:\n",
    "        model_names = np.append(model_names, str(item).split(\"(\")[0])\n",
    "    \n",
    "    ##########################\n",
    "    ##########################\n",
    "    ##########################\n",
    "    \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in estimator_list:\n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold, method=predict_method)\n",
    "        if method == 'soft':\n",
    "            base_array = base_array[:,1]\n",
    "        elif method == 'hard':\n",
    "            base_array = base_array\n",
    "        base_array_df = pd.DataFrame(base_array)\n",
    "        base_prediction = pd.concat([base_prediction,base_array_df],axis=1)\n",
    "        base_array = np.empty((0,0))\n",
    "        \n",
    "    #defining column names now\n",
    "    target_col_name = np.array(base_prediction.columns[0])\n",
    "    model_names = np.append(target_col_name, model_names)\n",
    "    base_prediction.columns = model_names #defining colum names now\n",
    "    \n",
    "    #defining data_X and data_y dataframe to be used in next stage.\n",
    "    \n",
    "    if restack:\n",
    "        data_X_ = X_train\n",
    "        data_X_ = data_X_.reset_index(drop=True)\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        data_X = pd.concat([data_X_,data_X],axis=1)\n",
    "        \n",
    "    elif restack == False:\n",
    "        data_X = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "        \n",
    "    data_y = base_prediction[base_prediction.columns[0]]\n",
    "    \n",
    "    #Correlation matrix of base_prediction\n",
    "    base_prediction_cor = base_prediction.drop(base_prediction.columns[0],axis=1)\n",
    "    base_prediction_cor = base_prediction_cor.corr()\n",
    "    \n",
    "    #Meta Modeling Starts Here\n",
    "    \n",
    "    model = meta_model #this defines model to be used below as model = meta_model (as captured above)\n",
    "\n",
    "    kf = StratifiedKFold(fold, random_state=seed) #capturing fold requested by user\n",
    "\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.average_precision_score(ytest,pred_prob)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "     \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "    \n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "    model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)  \n",
    "    \n",
    "    models = []\n",
    "    for i in estimator_list:\n",
    "        models.append(i)\n",
    "    \n",
    "    models.append(meta_model)\n",
    "    \n",
    "    if plot:\n",
    "        ax = sns.heatmap(base_prediction_cor, vmin=-0.5, vmax=1, center=0,cmap='magma', square=True, annot=True, \n",
    "                         linewidths=1)\n",
    "    \n",
    "    else:\n",
    "        display(model_results)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacknet(estimator_list,\n",
    "                    meta_model = None,\n",
    "                    fold = 10,\n",
    "                    round = 4,\n",
    "                    method = 'soft',\n",
    "                    restack = False):\n",
    "    \n",
    "    global base_array_df\n",
    "    \n",
    "    base_level = estimator_list[0]\n",
    "    inter_level = estimator_list[1:]\n",
    "    data_X = X_train\n",
    "    data_y = y_train\n",
    "    \n",
    "    #defining meta model\n",
    "    \n",
    "    if meta_model == None:\n",
    "        meta_model = LogisticRegression()\n",
    "    else:\n",
    "        meta_model = meta_model\n",
    "    \n",
    "    #Capturing the method of stacking required by user. method='soft' means 'predict_proba' else 'predict'\n",
    "    \n",
    "    if method == 'soft':\n",
    "        predict_method = 'predict_proba'\n",
    "    elif method == 'hard':\n",
    "        predict_method = 'predict'\n",
    "        \n",
    "        \n",
    "    base_array = np.zeros((0,0))\n",
    "    base_array_df = pd.DataFrame()\n",
    "    base_prediction = pd.DataFrame(y_train)\n",
    "    base_prediction = base_prediction.reset_index(drop=True)\n",
    "    \n",
    "    for model in base_level:\n",
    "                     \n",
    "        base_array = cross_val_predict(model,X_train,y_train,cv=fold, method=predict_method)\n",
    "        if method == 'soft':\n",
    "            base_array = base_array[:,1]\n",
    "        elif method == 'hard':\n",
    "            base_array = base_array\n",
    "        base_array = pd.DataFrame(base_array)\n",
    "        base_array_df = pd.concat([base_array_df, base_array], axis=1)\n",
    "        base_array = np.empty((0,0))  \n",
    "        \n",
    "    for level in inter_level:\n",
    "        \n",
    "        for model in level:\n",
    "            \n",
    "            base_array = cross_val_predict(model,base_array_df,base_prediction,cv=fold, method=predict_method)\n",
    "            if method == 'soft':\n",
    "                base_array = base_array[:,1]\n",
    "            elif method == 'hard':\n",
    "                base_array = base_array\n",
    "            base_array = pd.DataFrame(base_array)\n",
    "            base_array_df = pd.concat([base_array, base_array_df], axis=1)\n",
    "            base_array = np.empty((0,0))\n",
    "        \n",
    "        if restack == False:\n",
    "            base_array_df = base_array_df.iloc[:,:len(level)]\n",
    "        else:\n",
    "            base_array_df = base_array_df\n",
    "    \n",
    "    model = meta_model\n",
    "    \n",
    "    kf = StratifiedKFold(fold, random_state=seed) #capturing fold requested by user\n",
    "\n",
    "    score_auc =np.empty((0,0))\n",
    "    score_acc =np.empty((0,0))\n",
    "    score_recall =np.empty((0,0))\n",
    "    score_precision =np.empty((0,0))\n",
    "    score_f1 =np.empty((0,0))\n",
    "    score_kappa =np.empty((0,0))\n",
    "    avgs_auc =np.empty((0,0))\n",
    "    avgs_acc =np.empty((0,0))\n",
    "    avgs_recall =np.empty((0,0))\n",
    "    avgs_precision =np.empty((0,0))\n",
    "    avgs_f1 =np.empty((0,0))\n",
    "    avgs_kappa =np.empty((0,0))\n",
    "    \n",
    "    for train_i , test_i in kf.split(data_X,data_y):\n",
    "        \n",
    "        Xtrain,Xtest = data_X.iloc[train_i], data_X.iloc[test_i]\n",
    "        ytrain,ytest = data_y.iloc[train_i], data_y.iloc[test_i]\n",
    "\n",
    "        model.fit(Xtrain,ytrain)\n",
    "        pred_prob = model.predict_proba(Xtest)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred_ = model.predict(Xtest)\n",
    "        sca = metrics.accuracy_score(ytest,pred_)\n",
    "        sc = metrics.roc_auc_score(ytest,pred_prob)\n",
    "        recall = metrics.recall_score(ytest,pred_)\n",
    "        precision = metrics.average_precision_score(ytest,pred_prob)\n",
    "        kappa = cohen_kappa_score(ytest,pred_)\n",
    "        f1 = metrics.f1_score(ytest,pred_)\n",
    "        score_acc = np.append(score_acc,sca)\n",
    "        score_auc = np.append(score_auc,sc)\n",
    "        score_recall = np.append(score_recall,recall)\n",
    "        score_precision = np.append(score_precision,precision)\n",
    "        score_f1 =np.append(score_f1,f1)\n",
    "        score_kappa =np.append(score_kappa,kappa)\n",
    "     \n",
    "    mean_acc=np.mean(score_acc)\n",
    "    mean_auc=np.mean(score_auc)\n",
    "    mean_recall=np.mean(score_recall)\n",
    "    mean_precision=np.mean(score_precision)\n",
    "    mean_f1=np.mean(score_f1)\n",
    "    mean_kappa=np.mean(score_kappa)\n",
    "    std_acc=np.std(score_acc)\n",
    "    std_auc=np.std(score_auc)\n",
    "    std_recall=np.std(score_recall)\n",
    "    std_precision=np.std(score_precision)\n",
    "    std_f1=np.std(score_f1)\n",
    "    std_kappa=np.std(score_kappa)\n",
    "    \n",
    "    avgs_acc = np.append(avgs_acc, mean_acc)\n",
    "    avgs_acc = np.append(avgs_acc, std_acc) \n",
    "    avgs_auc = np.append(avgs_auc, mean_auc)\n",
    "    avgs_auc = np.append(avgs_auc, std_auc)\n",
    "    avgs_recall = np.append(avgs_recall, mean_recall)\n",
    "    avgs_recall = np.append(avgs_recall, std_recall)\n",
    "    avgs_precision = np.append(avgs_precision, mean_precision)\n",
    "    avgs_precision = np.append(avgs_precision, std_precision)\n",
    "    avgs_f1 = np.append(avgs_f1, mean_f1)\n",
    "    avgs_f1 = np.append(avgs_f1, std_f1)\n",
    "    avgs_kappa = np.append(avgs_kappa, mean_kappa)\n",
    "    avgs_kappa = np.append(avgs_kappa, std_kappa)\n",
    "      \n",
    "    model_results = pd.DataFrame({'Accuracy': score_acc, 'AUC': score_auc, 'Recall' : score_recall, 'Prec.' : score_precision , \n",
    "                     'F1' : score_f1, 'Kappa' : score_kappa})\n",
    "    model_avgs = pd.DataFrame({'Accuracy': avgs_acc, 'AUC': avgs_auc, 'Recall' : avgs_recall, 'Prec.' : avgs_precision , \n",
    "                     'F1' : avgs_f1, 'Kappa' : avgs_kappa},index=['Mean', 'SD'])\n",
    "  \n",
    "    model_results = model_results.append(model_avgs)\n",
    "    model_results = model_results.round(round)      \n",
    "    \n",
    "    display(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions End Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All the Models to see Top 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are first running all the models in model library as defined above in the function codes. Based on the results below we will select the first top 5 models and ensemble / tune them and will finally give the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4 th {\n",
       "          text-align: left;\n",
       "    }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col1 {\n",
       "            background-color:  yellow;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col6 {\n",
       "            background-color:  yellow;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col2 {\n",
       "            background-color:  yellow;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col5 {\n",
       "            background-color:  yellow;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col4 {\n",
       "            background-color:  yellow;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col3 {\n",
       "            background-color:  yellow;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col0 {\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col1 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col2 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col3 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col4 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col5 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }    #T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col6 {\n",
       "            : ;\n",
       "            text-align:  left;\n",
       "        }</style><table id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >AUC</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >Prec.</th>        <th class=\"col_heading level0 col5\" >F1</th>        <th class=\"col_heading level0 col6\" >Kappa</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col1\" class=\"data row0 col1\" >0.9348</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col2\" class=\"data row0 col2\" >0.9777</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col3\" class=\"data row0 col3\" >0.9076</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col4\" class=\"data row0 col4\" >0.9159</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col5\" class=\"data row0 col5\" >0.9116</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row0_col6\" class=\"data row0 col6\" >0.86</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col1\" class=\"data row1 col1\" >0.9342</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col2\" class=\"data row1 col2\" >0.9814</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col3\" class=\"data row1 col3\" >0.9226</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col4\" class=\"data row1 col4\" >0.9023</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col5\" class=\"data row1 col5\" >0.9123</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row1_col6\" class=\"data row1 col6\" >0.8596</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col0\" class=\"data row2 col0\" >Extra Trees Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col1\" class=\"data row2 col1\" >0.9251</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col2\" class=\"data row2 col2\" >0.9773</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col3\" class=\"data row2 col3\" >0.892</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col4\" class=\"data row2 col4\" >0.9051</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col5\" class=\"data row2 col5\" >0.8983</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row2_col6\" class=\"data row2 col6\" >0.839</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col0\" class=\"data row3 col0\" >Ada Boost Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col1\" class=\"data row3 col1\" >0.9142</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col2\" class=\"data row3 col2\" >0.9718</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col3\" class=\"data row3 col3\" >0.889</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col4\" class=\"data row3 col4\" >0.8809</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col5\" class=\"data row3 col5\" >0.8848</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row3_col6\" class=\"data row3 col6\" >0.8164</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col0\" class=\"data row4 col0\" >Decision Tree Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col1\" class=\"data row4 col1\" >0.9044</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col2\" class=\"data row4 col2\" >0.897</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col3\" class=\"data row4 col3\" >0.8686</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col4\" class=\"data row4 col4\" >0.8732</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col5\" class=\"data row4 col5\" >0.8707</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row4_col6\" class=\"data row4 col6\" >0.7948</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col0\" class=\"data row5 col0\" >Gaussian Process Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col1\" class=\"data row5 col1\" >0.9044</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col2\" class=\"data row5 col2\" >0.9279</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col3\" class=\"data row5 col3\" >0.8854</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col4\" class=\"data row5 col4\" >0.8612</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col5\" class=\"data row5 col5\" >0.8728</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row5_col6\" class=\"data row5 col6\" >0.7962</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col0\" class=\"data row6 col0\" >K Neighbors Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col1\" class=\"data row6 col1\" >0.8917</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col2\" class=\"data row6 col2\" >0.9473</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col3\" class=\"data row6 col3\" >0.874</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col4\" class=\"data row6 col4\" >0.8408</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col5\" class=\"data row6 col5\" >0.8567</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row6_col6\" class=\"data row6 col6\" >0.7698</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col0\" class=\"data row7 col0\" >SVM - Radial Kernel</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col1\" class=\"data row7 col1\" >0.8628</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col2\" class=\"data row7 col2\" >0.9503</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col3\" class=\"data row7 col3\" >0.688</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col4\" class=\"data row7 col4\" >0.9225</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col5\" class=\"data row7 col5\" >0.7878</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row7_col6\" class=\"data row7 col6\" >0.6896</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col1\" class=\"data row8 col1\" >0.7707</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col2\" class=\"data row8 col2\" >0.8239</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col3\" class=\"data row8 col3\" >0.6833</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col4\" class=\"data row8 col4\" >0.6938</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col5\" class=\"data row8 col5\" >0.6881</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row8_col6\" class=\"data row8 col6\" >0.5069</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col0\" class=\"data row9 col0\" >Ridge Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col1\" class=\"data row9 col1\" >0.7692</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col3\" class=\"data row9 col3\" >0.6743</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col4\" class=\"data row9 col4\" >0.6944</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col5\" class=\"data row9 col5\" >0.6838</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row9_col6\" class=\"data row9 col6\" >0.5022</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col0\" class=\"data row10 col0\" >MLP Classifier</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col1\" class=\"data row10 col1\" >0.7356</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col2\" class=\"data row10 col2\" >0.8494</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col3\" class=\"data row10 col3\" >0.4386</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col4\" class=\"data row10 col4\" >0.7935</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col5\" class=\"data row10 col5\" >0.5114</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row10_col6\" class=\"data row10 col6\" >0.3707</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col0\" class=\"data row11 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col1\" class=\"data row11 col1\" >0.7078</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col2\" class=\"data row11 col2\" >0.7653</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col3\" class=\"data row11 col3\" >0.3258</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col4\" class=\"data row11 col4\" >0.7351</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col5\" class=\"data row11 col5\" >0.4396</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row11_col6\" class=\"data row11 col6\" >0.2889</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col1\" class=\"data row12 col1\" >0.4274</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col2\" class=\"data row12 col2\" >0.7638</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col3\" class=\"data row12 col3\" >0.9694</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col4\" class=\"data row12 col4\" >0.3904</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col5\" class=\"data row12 col5\" >0.5566</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row12_col6\" class=\"data row12 col6\" >0.0595</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col1\" class=\"data row13 col1\" >0.4223</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col2\" class=\"data row13 col2\" >0.7703</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col3\" class=\"data row13 col3\" >0.976</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col4\" class=\"data row13 col4\" >0.3888</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col5\" class=\"data row13 col5\" >0.5561</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row13_col6\" class=\"data row13 col6\" >0.0551</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col0\" class=\"data row14 col0\" >SVM - Linear Kernel</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col1\" class=\"data row14 col1\" >0.3638</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col3\" class=\"data row14 col3\" >0.3313</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col4\" class=\"data row14 col4\" >0.19</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col5\" class=\"data row14 col5\" >0.2282</td>\n",
       "                        <td id=\"T_853ff37e_e22b_11e9_9744_a0a4c5932dd4row14_col6\" class=\"data row14 col6\" >-0.2714</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17b35944390>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Tune 5 Best Individual Models from the List above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Random Forest 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.8703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.8759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9578</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.9094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.8515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>0.8519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>0.8517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>0.8038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9348</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = create_model(estimator='rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Gradient Boosting Classifier 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.8533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.8904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.8758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.8301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.8596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbc = create_model(estimator='gbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Extra Trees Classifier 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>0.8773</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.7895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9317</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>0.8657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.8469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.8515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.8943</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>0.8839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.8613</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.8983</td>\n",
       "      <td>0.8390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "et = create_model(estimator='et')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Ada Boost Classifier 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.8589</td>\n",
       "      <td>0.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.7940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.8480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.7915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.8292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>0.8313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8931</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.7734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>0.8848</td>\n",
       "      <td>0.8164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ada = create_model(estimator='ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Decision Tree Classifier 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>0.7866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.7019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>0.8082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8629</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.8114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.7720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9131</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8953</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.7773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.7948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = create_model(estimator='dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Logistic Regression 10 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.4251</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.3954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6911</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.2934</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>0.2814</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>0.4012</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>0.3772</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.3286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7156</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.3892</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>0.3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.4398</td>\n",
       "      <td>0.8022</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.4149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.3631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.2938</td>\n",
       "      <td>0.1616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7078</td>\n",
       "      <td>0.7653</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.2889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.1336</td>\n",
       "      <td>0.1087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = create_model(estimator='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Bagging ensembling with the best 5 models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.8423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.8914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>0.9337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.8901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.8817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.8946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9131</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9356  0.9784  0.9162  0.9107  0.9134  0.8621\n",
       "1       0.9267  0.9791  0.8922  0.9085  0.9003  0.8423\n",
       "2       0.9489  0.9865  0.9521  0.9138  0.9326  0.8914\n",
       "3       0.9689  0.9913  0.9701  0.9474  0.9586  0.9337\n",
       "4       0.9556  0.9903  0.9641  0.9200  0.9415  0.9057\n",
       "5       0.9489  0.9872  0.9222  0.9390  0.9305  0.8901\n",
       "6       0.9444  0.9807  0.9401  0.9128  0.9263  0.8817\n",
       "7       0.9354  0.9846  0.9458  0.8870  0.9155  0.8633\n",
       "8       0.9510  0.9875  0.9277  0.9390  0.9333  0.8946\n",
       "9       0.9131  0.9742  0.9036  0.8671  0.8850  0.8152\n",
       "Mean    0.9428  0.9840  0.9334  0.9145  0.9237  0.8780\n",
       "SD      0.0149  0.0053  0.0242  0.0232  0.0200  0.0319"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=241, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging Random Forest\n",
    "ensemble_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.8677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>0.8955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>0.8963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.8336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.8387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.9207</td>\n",
       "      <td>0.8751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.8537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9222  0.9770  0.9042  0.8882  0.8961  0.8340\n",
       "1       0.9178  0.9732  0.8922  0.8869  0.8896  0.8241\n",
       "2       0.9378  0.9847  0.9341  0.9017  0.9176  0.8677\n",
       "3       0.9511  0.9882  0.9401  0.9290  0.9345  0.8955\n",
       "4       0.9511  0.9874  0.9581  0.9143  0.9357  0.8963\n",
       "5       0.9400  0.9850  0.9281  0.9118  0.9199  0.8719\n",
       "6       0.9222  0.9753  0.8982  0.8929  0.8955  0.8336\n",
       "7       0.9243  0.9811  0.9157  0.8837  0.8994  0.8387\n",
       "8       0.9421  0.9851  0.9096  0.9321  0.9207  0.8751\n",
       "9       0.9065  0.9723  0.8855  0.8647  0.8750  0.8003\n",
       "Mean    0.9315  0.9809  0.9166  0.9005  0.9084  0.8537\n",
       "SD      0.0143  0.0057  0.0219  0.0202  0.0191  0.0305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging GBC\n",
    "ensemble_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.8484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.8427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.8871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.8626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9207</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9289  0.9790  0.9162  0.8947  0.9053  0.8484\n",
       "1       0.9267  0.9773  0.8982  0.9036  0.9009  0.8427\n",
       "2       0.9467  0.9838  0.9581  0.9040  0.9302  0.8871\n",
       "3       0.9533  0.9915  0.9521  0.9244  0.9381  0.9006\n",
       "4       0.9511  0.9880  0.9521  0.9191  0.9353  0.8960\n",
       "5       0.9356  0.9849  0.9222  0.9059  0.9139  0.8624\n",
       "6       0.9356  0.9834  0.9222  0.9059  0.9139  0.8624\n",
       "7       0.9354  0.9824  0.9337  0.8960  0.9145  0.8626\n",
       "8       0.9376  0.9881  0.9096  0.9207  0.9152  0.8659\n",
       "9       0.9243  0.9749  0.9217  0.8793  0.9000  0.8391\n",
       "Mean    0.9375  0.9833  0.9286  0.9054  0.9167  0.8667\n",
       "SD      0.0095  0.0049  0.0189  0.0129  0.0129  0.0204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=241, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging Extra Trees\n",
    "ensemble_model(et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9067</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9067</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>0.8431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.8146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.8288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.8748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.7913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>0.8334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9067  0.9705  0.8683  0.8788  0.8735  0.7996\n",
       "1       0.9067  0.9657  0.8683  0.8788  0.8735  0.7996\n",
       "2       0.9267  0.9811  0.9042  0.8988  0.9015  0.8431\n",
       "3       0.9533  0.9837  0.9641  0.9148  0.9388  0.9011\n",
       "4       0.9289  0.9773  0.8982  0.9091  0.9036  0.8473\n",
       "5       0.9222  0.9753  0.9042  0.8882  0.8961  0.8340\n",
       "6       0.9133  0.9606  0.8862  0.8810  0.8836  0.8146\n",
       "7       0.9198  0.9678  0.9036  0.8824  0.8929  0.8288\n",
       "8       0.9421  0.9745  0.9036  0.9375  0.9202  0.8748\n",
       "9       0.9020  0.9625  0.8855  0.8547  0.8698  0.7913\n",
       "Mean    0.9222  0.9719  0.8986  0.8924  0.8954  0.8334\n",
       "SD      0.0155  0.0074  0.0256  0.0221  0.0209  0.0332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=241),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging Ada Boost\n",
    "ensemble_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.8765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9578</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.9094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.8654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.8612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9094</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.8588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9422  0.9688  0.9281  0.9172  0.9226  0.8765\n",
       "1       0.9156  0.9618  0.9042  0.8728  0.8882  0.8204\n",
       "2       0.9356  0.9801  0.9222  0.9059  0.9139  0.8624\n",
       "3       0.9578  0.9894  0.9401  0.9458  0.9429  0.9094\n",
       "4       0.9533  0.9884  0.9401  0.9345  0.9373  0.9001\n",
       "5       0.9378  0.9836  0.8922  0.9371  0.9141  0.8654\n",
       "6       0.9200  0.9770  0.8743  0.9068  0.8902  0.8273\n",
       "7       0.9354  0.9743  0.9096  0.9152  0.9124  0.8612\n",
       "8       0.9332  0.9798  0.8976  0.9198  0.9085  0.8559\n",
       "9       0.9109  0.9628  0.8855  0.8750  0.8802  0.8093\n",
       "Mean    0.9342  0.9766  0.9094  0.9130  0.9111  0.8588\n",
       "SD      0.0145  0.0092  0.0216  0.0231  0.0194  0.0309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=241,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging Decision Tree\n",
    "ensemble_model(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling Results\n",
    "### As we can see ensembling improved few model results. For e.g. AUC of decision tree before ensembling was 0.89 vs. after ensembling 0.9766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Top 5 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>0.3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7311</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>0.6257</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.4424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8067</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.4542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.7938</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>0.7022</td>\n",
       "      <td>0.5086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>0.6413</td>\n",
       "      <td>0.3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7661</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>0.5145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7461</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.7289</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.7642</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.5749</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7294</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.6166</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>0.4393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.6756  0.7420  0.6587  0.5528  0.6011  0.3312\n",
       "1       0.7311  0.7456  0.6707  0.6292  0.6493  0.4316\n",
       "2       0.7333  0.7710  0.7006  0.6257  0.6610  0.4424\n",
       "3       0.7356  0.8067  0.7365  0.6212  0.6740  0.4542\n",
       "4       0.7356  0.7783  0.7485  0.6188  0.6775  0.4568\n",
       "5       0.7644  0.7938  0.7485  0.6614  0.7022  0.5086\n",
       "6       0.7067  0.7521  0.7066  0.5871  0.6413  0.3967\n",
       "7       0.7661  0.8097  0.7651  0.6580  0.7075  0.5145\n",
       "8       0.7461  0.7660  0.7289  0.6368  0.6798  0.4710\n",
       "9       0.6993  0.7642  0.7169  0.5749  0.6381  0.3862\n",
       "Mean    0.7294  0.7730  0.7181  0.6166  0.6632  0.4393\n",
       "SD      0.0270  0.0229  0.0328  0.0333  0.0304  0.0533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l1', random_state=241,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune LR \n",
    "tune_model(estimator='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.9377</td>\n",
       "      <td>0.9004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9578</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>0.9196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9408</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.8334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.9246</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9533  0.9842  0.9461  0.9294  0.9377  0.9004\n",
       "1       0.9378  0.9823  0.9162  0.9162  0.9162  0.8667\n",
       "2       0.9578  0.9891  0.9581  0.9302  0.9440  0.9101\n",
       "3       0.9667  0.9916  0.9641  0.9471  0.9555  0.9289\n",
       "4       0.9622  0.9907  0.9641  0.9360  0.9499  0.9196\n",
       "5       0.9600  0.9896  0.9521  0.9408  0.9464  0.9145\n",
       "6       0.9356  0.9820  0.9222  0.9059  0.9139  0.8624\n",
       "7       0.9488  0.9859  0.9518  0.9133  0.9322  0.8910\n",
       "8       0.9555  0.9877  0.9398  0.9398  0.9398  0.9044\n",
       "9       0.9220  0.9774  0.9036  0.8876  0.8955  0.8334\n",
       "Mean    0.9500  0.9860  0.9418  0.9246  0.9331  0.8931\n",
       "SD      0.0133  0.0043  0.0200  0.0176  0.0179  0.0285"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.2, loss='exponential', max_depth=100,\n",
       "              max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=4, min_samples_split=7,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=140,\n",
       "              n_iter_no_change=None, presort='auto', random_state=241,\n",
       "              subsample=0.5, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune GBC\n",
    "tune_model(estimator='gbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.8484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9107</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.8855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.8765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.8652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.8334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.9094</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9289  0.9768  0.9162  0.8947  0.9053  0.8484\n",
       "1       0.9111  0.9721  0.8802  0.8802  0.8802  0.8096\n",
       "2       0.9356  0.9831  0.9162  0.9107  0.9134  0.8621\n",
       "3       0.9467  0.9895  0.9222  0.9333  0.9277  0.8855\n",
       "4       0.9400  0.9832  0.9222  0.9167  0.9194  0.8716\n",
       "5       0.9422  0.9859  0.9281  0.9172  0.9226  0.8765\n",
       "6       0.9289  0.9790  0.8982  0.9091  0.9036  0.8473\n",
       "7       0.9310  0.9797  0.9096  0.9042  0.9069  0.8520\n",
       "8       0.9376  0.9873  0.8976  0.9312  0.9141  0.8652\n",
       "9       0.9220  0.9725  0.9036  0.8876  0.8955  0.8334\n",
       "Mean    0.9324  0.9809  0.9094  0.9085  0.9089  0.8552\n",
       "SD      0.0099  0.0057  0.0138  0.0165  0.0132  0.0211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=30, max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=9,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "           oob_score=False, random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune ET \n",
    "tune_model(estimator='et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>0.8141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.7905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.8423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9156</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.8440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.7873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9197</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9133  0.9720  0.8802  0.8855  0.8829  0.8141\n",
       "1       0.9022  0.9650  0.8683  0.8683  0.8683  0.7905\n",
       "2       0.9222  0.9805  0.9042  0.8882  0.8961  0.8340\n",
       "3       0.9356  0.9784  0.9222  0.9059  0.9139  0.8624\n",
       "4       0.9244  0.9780  0.8982  0.8982  0.8982  0.8381\n",
       "5       0.9267  0.9770  0.8922  0.9085  0.9003  0.8423\n",
       "6       0.9156  0.9569  0.9042  0.8728  0.8882  0.8204\n",
       "7       0.9265  0.9738  0.9277  0.8800  0.9032  0.8440\n",
       "8       0.9310  0.9671  0.9096  0.9042  0.9069  0.8520\n",
       "9       0.8998  0.9658  0.8916  0.8457  0.8680  0.7873\n",
       "Mean    0.9197  0.9715  0.8998  0.8857  0.8926  0.8285\n",
       "SD      0.0112  0.0072  0.0171  0.0188  0.0148  0.0238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.6, n_estimators=150, random_state=241)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune ada \n",
    "tune_model(estimator='ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.9318</td>\n",
       "      <td>0.8909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.9377</td>\n",
       "      <td>0.9004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.9383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.9477</td>\n",
       "      <td>0.9153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.8863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>0.9042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.8911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9489  0.9827  0.9401  0.9235  0.9318  0.8909\n",
       "1       0.9400  0.9846  0.9281  0.9118  0.9199  0.8719\n",
       "2       0.9533  0.9903  0.9461  0.9294  0.9377  0.9004\n",
       "3       0.9711  0.9912  0.9701  0.9529  0.9614  0.9383\n",
       "4       0.9600  0.9901  0.9760  0.9209  0.9477  0.9153\n",
       "5       0.9467  0.9901  0.9401  0.9181  0.9290  0.8863\n",
       "6       0.9489  0.9853  0.9641  0.9045  0.9333  0.8920\n",
       "7       0.9465  0.9866  0.9639  0.8989  0.9302  0.8870\n",
       "8       0.9555  0.9902  0.9337  0.9451  0.9394  0.9042\n",
       "9       0.9176  0.9772  0.9036  0.8772  0.8902  0.8243\n",
       "Mean    0.9488  0.9868  0.9466  0.9182  0.9321  0.8911\n",
       "SD      0.0132  0.0043  0.0211  0.0209  0.0176  0.0282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criterion='entropy', max_depth=100, max_features='log2',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=2,\n",
       "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=30, n_jobs=None, oob_score=False,\n",
       "            random_state=241, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune RF \n",
    "tune_model(estimator='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.8136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.7837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.8656</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.8558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9637</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.8586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.8798</td>\n",
       "      <td>0.8065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.8367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.7852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9133  0.9389  0.8743  0.8902  0.8822  0.8136\n",
       "1       0.8978  0.9045  0.8922  0.8418  0.8663  0.7837\n",
       "2       0.9311  0.9691  0.9641  0.8656  0.9122  0.8558\n",
       "3       0.9333  0.9637  0.9341  0.8914  0.9123  0.8586\n",
       "4       0.9311  0.9582  0.9162  0.9000  0.9080  0.8530\n",
       "5       0.9089  0.9453  0.8982  0.8621  0.8798  0.8065\n",
       "6       0.8956  0.9315  0.8802  0.8448  0.8622  0.7781\n",
       "7       0.9354  0.9596  0.9458  0.8870  0.9155  0.8633\n",
       "8       0.9243  0.9509  0.8855  0.9074  0.8963  0.8367\n",
       "9       0.8998  0.9385  0.8675  0.8623  0.8649  0.7852\n",
       "Mean    0.9171  0.9460  0.9058  0.8753  0.8900  0.8234\n",
       "SD      0.0150  0.0180  0.0311  0.0218  0.0203  0.0322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "            max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=2,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=241, splitter='best')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tune DT\n",
    "tune_model(estimator='dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend Models - Building a Voting Classifier for Top 5 base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.7777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>0.8618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.8765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.8609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.8522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9244  0.9761  0.9042  0.8935  0.8988  0.8385\n",
       "1       0.8978  0.9684  0.8263  0.8903  0.8571  0.7777\n",
       "2       0.9467  0.9868  0.9281  0.9281  0.9281  0.8857\n",
       "3       0.9356  0.9852  0.9102  0.9157  0.9129  0.8618\n",
       "4       0.9422  0.9862  0.9281  0.9172  0.9226  0.8765\n",
       "5       0.9422  0.9890  0.9341  0.9123  0.9231  0.8768\n",
       "6       0.9178  0.9779  0.8982  0.8824  0.8902  0.8245\n",
       "7       0.9465  0.9832  0.9337  0.9226  0.9281  0.8856\n",
       "8       0.9354  0.9828  0.9036  0.9202  0.9119  0.8609\n",
       "9       0.9220  0.9723  0.9157  0.8786  0.8968  0.8342\n",
       "Mean    0.9311  0.9808  0.9082  0.9061  0.9070  0.8522\n",
       "SD      0.0148  0.0065  0.0300  0.0171  0.0210  0.0323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=241, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)),...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_models([lr,dt,ada,et,gbc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0.8912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9578</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>0.8955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9318</td>\n",
       "      <td>0.8909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.8899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.8753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.9356  0.9801  0.9222  0.9585  0.9139  0.8624\n",
       "1       0.9222  0.9730  0.8802  0.9508  0.8936  0.8323\n",
       "2       0.9489  0.9857  0.9461  0.9688  0.9322  0.8912\n",
       "3       0.9578  0.9892  0.9581  0.9808  0.9440  0.9101\n",
       "4       0.9511  0.9880  0.9401  0.9704  0.9345  0.8955\n",
       "5       0.9489  0.9909  0.9401  0.9841  0.9318  0.8909\n",
       "6       0.9356  0.9807  0.9222  0.9581  0.9139  0.8624\n",
       "7       0.9488  0.9846  0.9277  0.9651  0.9305  0.8899\n",
       "8       0.9465  0.9866  0.9096  0.9756  0.9264  0.8844\n",
       "9       0.9220  0.9752  0.9157  0.9526  0.8968  0.8342\n",
       "Mean    0.9417  0.9834  0.9262  0.9665  0.9218  0.8753\n",
       "SD      0.0117  0.0057  0.0208  0.0109  0.0158  0.0251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=241,\n",
       "             splitter='best'),\n",
       " AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=1.0, n_estimators=50, random_state=241),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=241, verbose=0, warm_start=False),\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               n_iter_no_change=None, presort='auto', random_state=241,\n",
       "               subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "           tol=0.0001, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_models([dt,ada,et,gbc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack_models([dt,ada,et,gbc], plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
